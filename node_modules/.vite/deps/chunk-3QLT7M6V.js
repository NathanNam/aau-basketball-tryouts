import {
  ExportResultCode,
  defaultResource,
  globalErrorHandler,
  hrTimeToMicroseconds,
  internal,
  millisToHrTime
} from "./chunk-MUUYURUO.js";
import {
  ValueType,
  context,
  createNoopMeter,
  diag
} from "./chunk-WWXHSA53.js";

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/AggregationTemporality.js
var AggregationTemporality;
(function(AggregationTemporality2) {
  AggregationTemporality2[AggregationTemporality2["DELTA"] = 0] = "DELTA";
  AggregationTemporality2[AggregationTemporality2["CUMULATIVE"] = 1] = "CUMULATIVE";
})(AggregationTemporality || (AggregationTemporality = {}));

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/MetricData.js
var InstrumentType;
(function(InstrumentType2) {
  InstrumentType2["COUNTER"] = "COUNTER";
  InstrumentType2["GAUGE"] = "GAUGE";
  InstrumentType2["HISTOGRAM"] = "HISTOGRAM";
  InstrumentType2["UP_DOWN_COUNTER"] = "UP_DOWN_COUNTER";
  InstrumentType2["OBSERVABLE_COUNTER"] = "OBSERVABLE_COUNTER";
  InstrumentType2["OBSERVABLE_GAUGE"] = "OBSERVABLE_GAUGE";
  InstrumentType2["OBSERVABLE_UP_DOWN_COUNTER"] = "OBSERVABLE_UP_DOWN_COUNTER";
})(InstrumentType || (InstrumentType = {}));
var DataPointType;
(function(DataPointType2) {
  DataPointType2[DataPointType2["HISTOGRAM"] = 0] = "HISTOGRAM";
  DataPointType2[DataPointType2["EXPONENTIAL_HISTOGRAM"] = 1] = "EXPONENTIAL_HISTOGRAM";
  DataPointType2[DataPointType2["GAUGE"] = 2] = "GAUGE";
  DataPointType2[DataPointType2["SUM"] = 3] = "SUM";
})(DataPointType || (DataPointType = {}));

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/utils.js
function isNotNullish(item) {
  return item !== void 0 && item !== null;
}
function hashAttributes(attributes) {
  let keys = Object.keys(attributes);
  if (keys.length === 0)
    return "";
  keys = keys.sort();
  return JSON.stringify(keys.map((key) => [key, attributes[key]]));
}
function instrumentationScopeId(instrumentationScope) {
  return `${instrumentationScope.name}:${instrumentationScope.version ?? ""}:${instrumentationScope.schemaUrl ?? ""}`;
}
var TimeoutError = class _TimeoutError extends Error {
  constructor(message) {
    super(message);
    Object.setPrototypeOf(this, _TimeoutError.prototype);
  }
};
function callWithTimeout(promise, timeout) {
  let timeoutHandle;
  const timeoutPromise = new Promise(function timeoutFunction(_resolve, reject) {
    timeoutHandle = setTimeout(function timeoutHandler() {
      reject(new TimeoutError("Operation timed out."));
    }, timeout);
  });
  return Promise.race([promise, timeoutPromise]).then((result) => {
    clearTimeout(timeoutHandle);
    return result;
  }, (reason) => {
    clearTimeout(timeoutHandle);
    throw reason;
  });
}
async function PromiseAllSettled(promises) {
  return Promise.all(promises.map(async (p) => {
    try {
      const ret = await p;
      return {
        status: "fulfilled",
        value: ret
      };
    } catch (e) {
      return {
        status: "rejected",
        reason: e
      };
    }
  }));
}
function isPromiseAllSettledRejectionResult(it) {
  return it.status === "rejected";
}
function FlatMap(arr, fn) {
  const result = [];
  arr.forEach((it) => {
    result.push(...fn(it));
  });
  return result;
}
function setEquals(lhs, rhs) {
  if (lhs.size !== rhs.size) {
    return false;
  }
  for (const item of lhs) {
    if (!rhs.has(item)) {
      return false;
    }
  }
  return true;
}
function binarySearchUB(arr, value) {
  let lo = 0;
  let hi = arr.length - 1;
  let ret = arr.length;
  while (hi >= lo) {
    const mid = lo + Math.trunc((hi - lo) / 2);
    if (arr[mid] < value) {
      lo = mid + 1;
    } else {
      ret = mid;
      hi = mid - 1;
    }
  }
  return ret;
}
function equalsCaseInsensitive(lhs, rhs) {
  return lhs.toLowerCase() === rhs.toLowerCase();
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/types.js
var AggregatorKind;
(function(AggregatorKind2) {
  AggregatorKind2[AggregatorKind2["DROP"] = 0] = "DROP";
  AggregatorKind2[AggregatorKind2["SUM"] = 1] = "SUM";
  AggregatorKind2[AggregatorKind2["LAST_VALUE"] = 2] = "LAST_VALUE";
  AggregatorKind2[AggregatorKind2["HISTOGRAM"] = 3] = "HISTOGRAM";
  AggregatorKind2[AggregatorKind2["EXPONENTIAL_HISTOGRAM"] = 4] = "EXPONENTIAL_HISTOGRAM";
})(AggregatorKind || (AggregatorKind = {}));

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/Drop.js
var DropAggregator = class {
  kind = AggregatorKind.DROP;
  createAccumulation() {
    return void 0;
  }
  merge(_previous, _delta) {
    return void 0;
  }
  diff(_previous, _current) {
    return void 0;
  }
  toMetricData(_descriptor, _aggregationTemporality, _accumulationByAttributes, _endTime) {
    return void 0;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/Histogram.js
function createNewEmptyCheckpoint(boundaries) {
  const counts = boundaries.map(() => 0);
  counts.push(0);
  return {
    buckets: {
      boundaries,
      counts
    },
    sum: 0,
    count: 0,
    hasMinMax: false,
    min: Infinity,
    max: -Infinity
  };
}
var HistogramAccumulation = class {
  startTime;
  _boundaries;
  _recordMinMax;
  _current;
  constructor(startTime, _boundaries, _recordMinMax = true, _current = createNewEmptyCheckpoint(_boundaries)) {
    this.startTime = startTime;
    this._boundaries = _boundaries;
    this._recordMinMax = _recordMinMax;
    this._current = _current;
  }
  record(value) {
    if (Number.isNaN(value)) {
      return;
    }
    this._current.count += 1;
    this._current.sum += value;
    if (this._recordMinMax) {
      this._current.min = Math.min(value, this._current.min);
      this._current.max = Math.max(value, this._current.max);
      this._current.hasMinMax = true;
    }
    const idx = binarySearchUB(this._boundaries, value);
    this._current.buckets.counts[idx] += 1;
  }
  setStartTime(startTime) {
    this.startTime = startTime;
  }
  toPointValue() {
    return this._current;
  }
};
var HistogramAggregator = class {
  _boundaries;
  _recordMinMax;
  kind = AggregatorKind.HISTOGRAM;
  /**
   * @param _boundaries sorted upper bounds of recorded values.
   * @param _recordMinMax If set to true, min and max will be recorded. Otherwise, min and max will not be recorded.
   */
  constructor(_boundaries, _recordMinMax) {
    this._boundaries = _boundaries;
    this._recordMinMax = _recordMinMax;
  }
  createAccumulation(startTime) {
    return new HistogramAccumulation(startTime, this._boundaries, this._recordMinMax);
  }
  /**
   * Return the result of the merge of two histogram accumulations. As long as one Aggregator
   * instance produces all Accumulations with constant boundaries we don't need to worry about
   * merging accumulations with different boundaries.
   */
  merge(previous, delta) {
    const previousValue = previous.toPointValue();
    const deltaValue = delta.toPointValue();
    const previousCounts = previousValue.buckets.counts;
    const deltaCounts = deltaValue.buckets.counts;
    const mergedCounts = new Array(previousCounts.length);
    for (let idx = 0; idx < previousCounts.length; idx++) {
      mergedCounts[idx] = previousCounts[idx] + deltaCounts[idx];
    }
    let min = Infinity;
    let max = -Infinity;
    if (this._recordMinMax) {
      if (previousValue.hasMinMax && deltaValue.hasMinMax) {
        min = Math.min(previousValue.min, deltaValue.min);
        max = Math.max(previousValue.max, deltaValue.max);
      } else if (previousValue.hasMinMax) {
        min = previousValue.min;
        max = previousValue.max;
      } else if (deltaValue.hasMinMax) {
        min = deltaValue.min;
        max = deltaValue.max;
      }
    }
    return new HistogramAccumulation(previous.startTime, previousValue.buckets.boundaries, this._recordMinMax, {
      buckets: {
        boundaries: previousValue.buckets.boundaries,
        counts: mergedCounts
      },
      count: previousValue.count + deltaValue.count,
      sum: previousValue.sum + deltaValue.sum,
      hasMinMax: this._recordMinMax && (previousValue.hasMinMax || deltaValue.hasMinMax),
      min,
      max
    });
  }
  /**
   * Returns a new DELTA aggregation by comparing two cumulative measurements.
   */
  diff(previous, current) {
    const previousValue = previous.toPointValue();
    const currentValue = current.toPointValue();
    const previousCounts = previousValue.buckets.counts;
    const currentCounts = currentValue.buckets.counts;
    const diffedCounts = new Array(previousCounts.length);
    for (let idx = 0; idx < previousCounts.length; idx++) {
      diffedCounts[idx] = currentCounts[idx] - previousCounts[idx];
    }
    return new HistogramAccumulation(current.startTime, previousValue.buckets.boundaries, this._recordMinMax, {
      buckets: {
        boundaries: previousValue.buckets.boundaries,
        counts: diffedCounts
      },
      count: currentValue.count - previousValue.count,
      sum: currentValue.sum - previousValue.sum,
      hasMinMax: false,
      min: Infinity,
      max: -Infinity
    });
  }
  toMetricData(descriptor, aggregationTemporality, accumulationByAttributes, endTime) {
    return {
      descriptor,
      aggregationTemporality,
      dataPointType: DataPointType.HISTOGRAM,
      dataPoints: accumulationByAttributes.map(([attributes, accumulation]) => {
        const pointValue = accumulation.toPointValue();
        const allowsNegativeValues = descriptor.type === InstrumentType.GAUGE || descriptor.type === InstrumentType.UP_DOWN_COUNTER || descriptor.type === InstrumentType.OBSERVABLE_GAUGE || descriptor.type === InstrumentType.OBSERVABLE_UP_DOWN_COUNTER;
        return {
          attributes,
          startTime: accumulation.startTime,
          endTime,
          value: {
            min: pointValue.hasMinMax ? pointValue.min : void 0,
            max: pointValue.hasMinMax ? pointValue.max : void 0,
            sum: !allowsNegativeValues ? pointValue.sum : void 0,
            buckets: pointValue.buckets,
            count: pointValue.count
          }
        };
      })
    };
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/Buckets.js
var Buckets = class _Buckets {
  backing;
  indexBase;
  indexStart;
  indexEnd;
  /**
   * The term index refers to the number of the exponential histogram bucket
   * used to determine its boundaries. The lower boundary of a bucket is
   * determined by base ** index and the upper boundary of a bucket is
   * determined by base ** (index + 1). index values are signed to account
   * for values less than or equal to 1.
   *
   * indexBase is the index of the 0th position in the
   * backing array, i.e., backing[0] is the count
   * in the bucket with index `indexBase`.
   *
   * indexStart is the smallest index value represented
   * in the backing array.
   *
   * indexEnd is the largest index value represented in
   * the backing array.
   */
  constructor(backing = new BucketsBacking(), indexBase = 0, indexStart = 0, indexEnd = 0) {
    this.backing = backing;
    this.indexBase = indexBase;
    this.indexStart = indexStart;
    this.indexEnd = indexEnd;
  }
  /**
   * Offset is the bucket index of the smallest entry in the counts array
   * @returns {number}
   */
  get offset() {
    return this.indexStart;
  }
  /**
   * Buckets is a view into the backing array.
   * @returns {number}
   */
  get length() {
    if (this.backing.length === 0) {
      return 0;
    }
    if (this.indexEnd === this.indexStart && this.at(0) === 0) {
      return 0;
    }
    return this.indexEnd - this.indexStart + 1;
  }
  /**
   * An array of counts, where count[i] carries the count
   * of the bucket at index (offset+i).  count[i] is the count of
   * values greater than base^(offset+i) and less than or equal to
   * base^(offset+i+1).
   * @returns {number} The logical counts based on the backing array
   */
  counts() {
    return Array.from({ length: this.length }, (_, i) => this.at(i));
  }
  /**
   * At returns the count of the bucket at a position in the logical
   * array of counts.
   * @param position
   * @returns {number}
   */
  at(position) {
    const bias = this.indexBase - this.indexStart;
    if (position < bias) {
      position += this.backing.length;
    }
    position -= bias;
    return this.backing.countAt(position);
  }
  /**
   * incrementBucket increments the backing array index by `increment`
   * @param bucketIndex
   * @param increment
   */
  incrementBucket(bucketIndex, increment) {
    this.backing.increment(bucketIndex, increment);
  }
  /**
   * decrementBucket decrements the backing array index by `decrement`
   * if decrement is greater than the current value, it's set to 0.
   * @param bucketIndex
   * @param decrement
   */
  decrementBucket(bucketIndex, decrement) {
    this.backing.decrement(bucketIndex, decrement);
  }
  /**
   * trim removes leading and / or trailing zero buckets (which can occur
   * after diffing two histos) and rotates the backing array so that the
   * smallest non-zero index is in the 0th position of the backing array
   */
  trim() {
    for (let i = 0; i < this.length; i++) {
      if (this.at(i) !== 0) {
        this.indexStart += i;
        break;
      } else if (i === this.length - 1) {
        this.indexStart = this.indexEnd = this.indexBase = 0;
        return;
      }
    }
    for (let i = this.length - 1; i >= 0; i--) {
      if (this.at(i) !== 0) {
        this.indexEnd -= this.length - i - 1;
        break;
      }
    }
    this._rotate();
  }
  /**
   * downscale first rotates, then collapses 2**`by`-to-1 buckets.
   * @param by
   */
  downscale(by) {
    this._rotate();
    const size = 1 + this.indexEnd - this.indexStart;
    const each = 1 << by;
    let inpos = 0;
    let outpos = 0;
    for (let pos = this.indexStart; pos <= this.indexEnd; ) {
      let mod = pos % each;
      if (mod < 0) {
        mod += each;
      }
      for (let i = mod; i < each && inpos < size; i++) {
        this._relocateBucket(outpos, inpos);
        inpos++;
        pos++;
      }
      outpos++;
    }
    this.indexStart >>= by;
    this.indexEnd >>= by;
    this.indexBase = this.indexStart;
  }
  /**
   * Clone returns a deep copy of Buckets
   * @returns {Buckets}
   */
  clone() {
    return new _Buckets(this.backing.clone(), this.indexBase, this.indexStart, this.indexEnd);
  }
  /**
   * _rotate shifts the backing array contents so that indexStart ==
   * indexBase to simplify the downscale logic.
   */
  _rotate() {
    const bias = this.indexBase - this.indexStart;
    if (bias === 0) {
      return;
    } else if (bias > 0) {
      this.backing.reverse(0, this.backing.length);
      this.backing.reverse(0, bias);
      this.backing.reverse(bias, this.backing.length);
    } else {
      this.backing.reverse(0, this.backing.length);
      this.backing.reverse(0, this.backing.length + bias);
    }
    this.indexBase = this.indexStart;
  }
  /**
   * _relocateBucket adds the count in counts[src] to counts[dest] and
   * resets count[src] to zero.
   */
  _relocateBucket(dest, src) {
    if (dest === src) {
      return;
    }
    this.incrementBucket(dest, this.backing.emptyBucket(src));
  }
};
var BucketsBacking = class _BucketsBacking {
  _counts;
  constructor(_counts = [0]) {
    this._counts = _counts;
  }
  /**
   * length returns the physical size of the backing array, which
   * is >= buckets.length()
   */
  get length() {
    return this._counts.length;
  }
  /**
   * countAt returns the count in a specific bucket
   */
  countAt(pos) {
    return this._counts[pos];
  }
  /**
   * growTo grows a backing array and copies old entries
   * into their correct new positions.
   */
  growTo(newSize, oldPositiveLimit, newPositiveLimit) {
    const tmp = new Array(newSize).fill(0);
    tmp.splice(newPositiveLimit, this._counts.length - oldPositiveLimit, ...this._counts.slice(oldPositiveLimit));
    tmp.splice(0, oldPositiveLimit, ...this._counts.slice(0, oldPositiveLimit));
    this._counts = tmp;
  }
  /**
   * reverse the items in the backing array in the range [from, limit).
   */
  reverse(from, limit) {
    const num = Math.floor((from + limit) / 2) - from;
    for (let i = 0; i < num; i++) {
      const tmp = this._counts[from + i];
      this._counts[from + i] = this._counts[limit - i - 1];
      this._counts[limit - i - 1] = tmp;
    }
  }
  /**
   * emptyBucket empties the count from a bucket, for
   * moving into another.
   */
  emptyBucket(src) {
    const tmp = this._counts[src];
    this._counts[src] = 0;
    return tmp;
  }
  /**
   * increments a bucket by `increment`
   */
  increment(bucketIndex, increment) {
    this._counts[bucketIndex] += increment;
  }
  /**
   * decrements a bucket by `decrement`
   */
  decrement(bucketIndex, decrement) {
    if (this._counts[bucketIndex] >= decrement) {
      this._counts[bucketIndex] -= decrement;
    } else {
      this._counts[bucketIndex] = 0;
    }
  }
  /**
   * clone returns a deep copy of BucketsBacking
   */
  clone() {
    return new _BucketsBacking([...this._counts]);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/mapping/ieee754.js
var SIGNIFICAND_WIDTH = 52;
var EXPONENT_MASK = 2146435072;
var SIGNIFICAND_MASK = 1048575;
var EXPONENT_BIAS = 1023;
var MIN_NORMAL_EXPONENT = -EXPONENT_BIAS + 1;
var MAX_NORMAL_EXPONENT = EXPONENT_BIAS;
var MIN_VALUE = Math.pow(2, -1022);
function getNormalBase2(value) {
  const dv = new DataView(new ArrayBuffer(8));
  dv.setFloat64(0, value);
  const hiBits = dv.getUint32(0);
  const expBits = (hiBits & EXPONENT_MASK) >> 20;
  return expBits - EXPONENT_BIAS;
}
function getSignificand(value) {
  const dv = new DataView(new ArrayBuffer(8));
  dv.setFloat64(0, value);
  const hiBits = dv.getUint32(0);
  const loBits = dv.getUint32(4);
  const significandHiBits = (hiBits & SIGNIFICAND_MASK) * Math.pow(2, 32);
  return significandHiBits + loBits;
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/util.js
function ldexp(frac, exp) {
  if (frac === 0 || frac === Number.POSITIVE_INFINITY || frac === Number.NEGATIVE_INFINITY || Number.isNaN(frac)) {
    return frac;
  }
  return frac * Math.pow(2, exp);
}
function nextGreaterSquare(v) {
  v--;
  v |= v >> 1;
  v |= v >> 2;
  v |= v >> 4;
  v |= v >> 8;
  v |= v >> 16;
  v++;
  return v;
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/mapping/types.js
var MappingError = class extends Error {
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/mapping/ExponentMapping.js
var ExponentMapping = class {
  _shift;
  constructor(scale) {
    this._shift = -scale;
  }
  /**
   * Maps positive floating point values to indexes corresponding to scale
   * @param value
   * @returns {number} index for provided value at the current scale
   */
  mapToIndex(value) {
    if (value < MIN_VALUE) {
      return this._minNormalLowerBoundaryIndex();
    }
    const exp = getNormalBase2(value);
    const correction = this._rightShift(getSignificand(value) - 1, SIGNIFICAND_WIDTH);
    return exp + correction >> this._shift;
  }
  /**
   * Returns the lower bucket boundary for the given index for scale
   *
   * @param index
   * @returns {number}
   */
  lowerBoundary(index) {
    const minIndex = this._minNormalLowerBoundaryIndex();
    if (index < minIndex) {
      throw new MappingError(`underflow: ${index} is < minimum lower boundary: ${minIndex}`);
    }
    const maxIndex = this._maxNormalLowerBoundaryIndex();
    if (index > maxIndex) {
      throw new MappingError(`overflow: ${index} is > maximum lower boundary: ${maxIndex}`);
    }
    return ldexp(1, index << this._shift);
  }
  /**
   * The scale used by this mapping
   * @returns {number}
   */
  get scale() {
    if (this._shift === 0) {
      return 0;
    }
    return -this._shift;
  }
  _minNormalLowerBoundaryIndex() {
    let index = MIN_NORMAL_EXPONENT >> this._shift;
    if (this._shift < 2) {
      index--;
    }
    return index;
  }
  _maxNormalLowerBoundaryIndex() {
    return MAX_NORMAL_EXPONENT >> this._shift;
  }
  _rightShift(value, shift) {
    return Math.floor(value * Math.pow(2, -shift));
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/mapping/LogarithmMapping.js
var LogarithmMapping = class {
  _scale;
  _scaleFactor;
  _inverseFactor;
  constructor(scale) {
    this._scale = scale;
    this._scaleFactor = ldexp(Math.LOG2E, scale);
    this._inverseFactor = ldexp(Math.LN2, -scale);
  }
  /**
   * Maps positive floating point values to indexes corresponding to scale
   * @param value
   * @returns {number} index for provided value at the current scale
   */
  mapToIndex(value) {
    if (value <= MIN_VALUE) {
      return this._minNormalLowerBoundaryIndex() - 1;
    }
    if (getSignificand(value) === 0) {
      const exp = getNormalBase2(value);
      return (exp << this._scale) - 1;
    }
    const index = Math.floor(Math.log(value) * this._scaleFactor);
    const maxIndex = this._maxNormalLowerBoundaryIndex();
    if (index >= maxIndex) {
      return maxIndex;
    }
    return index;
  }
  /**
   * Returns the lower bucket boundary for the given index for scale
   *
   * @param index
   * @returns {number}
   */
  lowerBoundary(index) {
    const maxIndex = this._maxNormalLowerBoundaryIndex();
    if (index >= maxIndex) {
      if (index === maxIndex) {
        return 2 * Math.exp((index - (1 << this._scale)) / this._scaleFactor);
      }
      throw new MappingError(`overflow: ${index} is > maximum lower boundary: ${maxIndex}`);
    }
    const minIndex = this._minNormalLowerBoundaryIndex();
    if (index <= minIndex) {
      if (index === minIndex) {
        return MIN_VALUE;
      } else if (index === minIndex - 1) {
        return Math.exp((index + (1 << this._scale)) / this._scaleFactor) / 2;
      }
      throw new MappingError(`overflow: ${index} is < minimum lower boundary: ${minIndex}`);
    }
    return Math.exp(index * this._inverseFactor);
  }
  /**
   * The scale used by this mapping
   * @returns {number}
   */
  get scale() {
    return this._scale;
  }
  _minNormalLowerBoundaryIndex() {
    return MIN_NORMAL_EXPONENT << this._scale;
  }
  _maxNormalLowerBoundaryIndex() {
    return (MAX_NORMAL_EXPONENT + 1 << this._scale) - 1;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/exponential-histogram/mapping/getMapping.js
var MIN_SCALE = -10;
var MAX_SCALE = 20;
var PREBUILT_MAPPINGS = Array.from({ length: 31 }, (_, i) => {
  if (i > 10) {
    return new LogarithmMapping(i - 10);
  }
  return new ExponentMapping(i - 10);
});
function getMapping(scale) {
  if (scale > MAX_SCALE || scale < MIN_SCALE) {
    throw new MappingError(`expected scale >= ${MIN_SCALE} && <= ${MAX_SCALE}, got: ${scale}`);
  }
  return PREBUILT_MAPPINGS[scale + 10];
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/ExponentialHistogram.js
var HighLow = class _HighLow {
  low;
  high;
  static combine(h1, h2) {
    return new _HighLow(Math.min(h1.low, h2.low), Math.max(h1.high, h2.high));
  }
  constructor(low, high) {
    this.low = low;
    this.high = high;
  }
};
var MAX_SCALE2 = 20;
var DEFAULT_MAX_SIZE = 160;
var MIN_MAX_SIZE = 2;
var ExponentialHistogramAccumulation = class _ExponentialHistogramAccumulation {
  startTime;
  _maxSize;
  _recordMinMax;
  _sum;
  _count;
  _zeroCount;
  _min;
  _max;
  _positive;
  _negative;
  _mapping;
  constructor(startTime, _maxSize = DEFAULT_MAX_SIZE, _recordMinMax = true, _sum = 0, _count = 0, _zeroCount = 0, _min = Number.POSITIVE_INFINITY, _max = Number.NEGATIVE_INFINITY, _positive = new Buckets(), _negative = new Buckets(), _mapping = getMapping(MAX_SCALE2)) {
    this.startTime = startTime;
    this._maxSize = _maxSize;
    this._recordMinMax = _recordMinMax;
    this._sum = _sum;
    this._count = _count;
    this._zeroCount = _zeroCount;
    this._min = _min;
    this._max = _max;
    this._positive = _positive;
    this._negative = _negative;
    this._mapping = _mapping;
    if (this._maxSize < MIN_MAX_SIZE) {
      diag.warn(`Exponential Histogram Max Size set to ${this._maxSize},                 changing to the minimum size of: ${MIN_MAX_SIZE}`);
      this._maxSize = MIN_MAX_SIZE;
    }
  }
  /**
   * record updates a histogram with a single count
   * @param {Number} value
   */
  record(value) {
    this.updateByIncrement(value, 1);
  }
  /**
   * Sets the start time for this accumulation
   * @param {HrTime} startTime
   */
  setStartTime(startTime) {
    this.startTime = startTime;
  }
  /**
   * Returns the datapoint representation of this accumulation
   * @param {HrTime} startTime
   */
  toPointValue() {
    return {
      hasMinMax: this._recordMinMax,
      min: this.min,
      max: this.max,
      sum: this.sum,
      positive: {
        offset: this.positive.offset,
        bucketCounts: this.positive.counts()
      },
      negative: {
        offset: this.negative.offset,
        bucketCounts: this.negative.counts()
      },
      count: this.count,
      scale: this.scale,
      zeroCount: this.zeroCount
    };
  }
  /**
   * @returns {Number} The sum of values recorded by this accumulation
   */
  get sum() {
    return this._sum;
  }
  /**
   * @returns {Number} The minimum value recorded by this accumulation
   */
  get min() {
    return this._min;
  }
  /**
   * @returns {Number} The maximum value recorded by this accumulation
   */
  get max() {
    return this._max;
  }
  /**
   * @returns {Number} The count of values recorded by this accumulation
   */
  get count() {
    return this._count;
  }
  /**
   * @returns {Number} The number of 0 values recorded by this accumulation
   */
  get zeroCount() {
    return this._zeroCount;
  }
  /**
   * @returns {Number} The scale used by this accumulation
   */
  get scale() {
    if (this._count === this._zeroCount) {
      return 0;
    }
    return this._mapping.scale;
  }
  /**
   * positive holds the positive values
   * @returns {Buckets}
   */
  get positive() {
    return this._positive;
  }
  /**
   * negative holds the negative values by their absolute value
   * @returns {Buckets}
   */
  get negative() {
    return this._negative;
  }
  /**
   * updateByIncr supports updating a histogram with a non-negative
   * increment.
   * @param value
   * @param increment
   */
  updateByIncrement(value, increment) {
    if (Number.isNaN(value)) {
      return;
    }
    if (value > this._max) {
      this._max = value;
    }
    if (value < this._min) {
      this._min = value;
    }
    this._count += increment;
    if (value === 0) {
      this._zeroCount += increment;
      return;
    }
    this._sum += value * increment;
    if (value > 0) {
      this._updateBuckets(this._positive, value, increment);
    } else {
      this._updateBuckets(this._negative, -value, increment);
    }
  }
  /**
   * merge combines data from previous value into self
   * @param {ExponentialHistogramAccumulation} previous
   */
  merge(previous) {
    if (this._count === 0) {
      this._min = previous.min;
      this._max = previous.max;
    } else if (previous.count !== 0) {
      if (previous.min < this.min) {
        this._min = previous.min;
      }
      if (previous.max > this.max) {
        this._max = previous.max;
      }
    }
    this.startTime = previous.startTime;
    this._sum += previous.sum;
    this._count += previous.count;
    this._zeroCount += previous.zeroCount;
    const minScale = this._minScale(previous);
    this._downscale(this.scale - minScale);
    this._mergeBuckets(this.positive, previous, previous.positive, minScale);
    this._mergeBuckets(this.negative, previous, previous.negative, minScale);
  }
  /**
   * diff subtracts other from self
   * @param {ExponentialHistogramAccumulation} other
   */
  diff(other) {
    this._min = Infinity;
    this._max = -Infinity;
    this._sum -= other.sum;
    this._count -= other.count;
    this._zeroCount -= other.zeroCount;
    const minScale = this._minScale(other);
    this._downscale(this.scale - minScale);
    this._diffBuckets(this.positive, other, other.positive, minScale);
    this._diffBuckets(this.negative, other, other.negative, minScale);
  }
  /**
   * clone returns a deep copy of self
   * @returns {ExponentialHistogramAccumulation}
   */
  clone() {
    return new _ExponentialHistogramAccumulation(this.startTime, this._maxSize, this._recordMinMax, this._sum, this._count, this._zeroCount, this._min, this._max, this.positive.clone(), this.negative.clone(), this._mapping);
  }
  /**
   * _updateBuckets maps the incoming value to a bucket index for the current
   * scale. If the bucket index is outside of the range of the backing array,
   * it will rescale the backing array and update the mapping for the new scale.
   */
  _updateBuckets(buckets, value, increment) {
    let index = this._mapping.mapToIndex(value);
    let rescalingNeeded = false;
    let high = 0;
    let low = 0;
    if (buckets.length === 0) {
      buckets.indexStart = index;
      buckets.indexEnd = buckets.indexStart;
      buckets.indexBase = buckets.indexStart;
    } else if (index < buckets.indexStart && buckets.indexEnd - index >= this._maxSize) {
      rescalingNeeded = true;
      low = index;
      high = buckets.indexEnd;
    } else if (index > buckets.indexEnd && index - buckets.indexStart >= this._maxSize) {
      rescalingNeeded = true;
      low = buckets.indexStart;
      high = index;
    }
    if (rescalingNeeded) {
      const change = this._changeScale(high, low);
      this._downscale(change);
      index = this._mapping.mapToIndex(value);
    }
    this._incrementIndexBy(buckets, index, increment);
  }
  /**
   * _incrementIndexBy increments the count of the bucket specified by `index`.
   * If the index is outside of the range [buckets.indexStart, buckets.indexEnd]
   * the boundaries of the backing array will be adjusted and more buckets will
   * be added if needed.
   */
  _incrementIndexBy(buckets, index, increment) {
    if (increment === 0) {
      return;
    }
    if (buckets.length === 0) {
      buckets.indexStart = buckets.indexEnd = buckets.indexBase = index;
    }
    if (index < buckets.indexStart) {
      const span = buckets.indexEnd - index;
      if (span >= buckets.backing.length) {
        this._grow(buckets, span + 1);
      }
      buckets.indexStart = index;
    } else if (index > buckets.indexEnd) {
      const span = index - buckets.indexStart;
      if (span >= buckets.backing.length) {
        this._grow(buckets, span + 1);
      }
      buckets.indexEnd = index;
    }
    let bucketIndex = index - buckets.indexBase;
    if (bucketIndex < 0) {
      bucketIndex += buckets.backing.length;
    }
    buckets.incrementBucket(bucketIndex, increment);
  }
  /**
   * grow resizes the backing array by doubling in size up to maxSize.
   * This extends the array with a bunch of zeros and copies the
   * existing counts to the same position.
   */
  _grow(buckets, needed) {
    const size = buckets.backing.length;
    const bias = buckets.indexBase - buckets.indexStart;
    const oldPositiveLimit = size - bias;
    let newSize = nextGreaterSquare(needed);
    if (newSize > this._maxSize) {
      newSize = this._maxSize;
    }
    const newPositiveLimit = newSize - bias;
    buckets.backing.growTo(newSize, oldPositiveLimit, newPositiveLimit);
  }
  /**
   * _changeScale computes how much downscaling is needed by shifting the
   * high and low values until they are separated by no more than size.
   */
  _changeScale(high, low) {
    let change = 0;
    while (high - low >= this._maxSize) {
      high >>= 1;
      low >>= 1;
      change++;
    }
    return change;
  }
  /**
   * _downscale subtracts `change` from the current mapping scale.
   */
  _downscale(change) {
    if (change === 0) {
      return;
    }
    if (change < 0) {
      throw new Error(`impossible change of scale: ${this.scale}`);
    }
    const newScale = this._mapping.scale - change;
    this._positive.downscale(change);
    this._negative.downscale(change);
    this._mapping = getMapping(newScale);
  }
  /**
   * _minScale is used by diff and merge to compute an ideal combined scale
   */
  _minScale(other) {
    const minScale = Math.min(this.scale, other.scale);
    const highLowPos = HighLow.combine(this._highLowAtScale(this.positive, this.scale, minScale), this._highLowAtScale(other.positive, other.scale, minScale));
    const highLowNeg = HighLow.combine(this._highLowAtScale(this.negative, this.scale, minScale), this._highLowAtScale(other.negative, other.scale, minScale));
    return Math.min(minScale - this._changeScale(highLowPos.high, highLowPos.low), minScale - this._changeScale(highLowNeg.high, highLowNeg.low));
  }
  /**
   * _highLowAtScale is used by diff and merge to compute an ideal combined scale.
   */
  _highLowAtScale(buckets, currentScale, newScale) {
    if (buckets.length === 0) {
      return new HighLow(0, -1);
    }
    const shift = currentScale - newScale;
    return new HighLow(buckets.indexStart >> shift, buckets.indexEnd >> shift);
  }
  /**
   * _mergeBuckets translates index values from another histogram and
   * adds the values into the corresponding buckets of this histogram.
   */
  _mergeBuckets(ours, other, theirs, scale) {
    const theirOffset = theirs.offset;
    const theirChange = other.scale - scale;
    for (let i = 0; i < theirs.length; i++) {
      this._incrementIndexBy(ours, theirOffset + i >> theirChange, theirs.at(i));
    }
  }
  /**
   * _diffBuckets translates index values from another histogram and
   * subtracts the values in the corresponding buckets of this histogram.
   */
  _diffBuckets(ours, other, theirs, scale) {
    const theirOffset = theirs.offset;
    const theirChange = other.scale - scale;
    for (let i = 0; i < theirs.length; i++) {
      const ourIndex = theirOffset + i >> theirChange;
      let bucketIndex = ourIndex - ours.indexBase;
      if (bucketIndex < 0) {
        bucketIndex += ours.backing.length;
      }
      ours.decrementBucket(bucketIndex, theirs.at(i));
    }
    ours.trim();
  }
};
var ExponentialHistogramAggregator = class {
  _maxSize;
  _recordMinMax;
  kind = AggregatorKind.EXPONENTIAL_HISTOGRAM;
  /**
   * @param _maxSize Maximum number of buckets for each of the positive
   *    and negative ranges, exclusive of the zero-bucket.
   * @param _recordMinMax If set to true, min and max will be recorded.
   *    Otherwise, min and max will not be recorded.
   */
  constructor(_maxSize, _recordMinMax) {
    this._maxSize = _maxSize;
    this._recordMinMax = _recordMinMax;
  }
  createAccumulation(startTime) {
    return new ExponentialHistogramAccumulation(startTime, this._maxSize, this._recordMinMax);
  }
  /**
   * Return the result of the merge of two exponential histogram accumulations.
   */
  merge(previous, delta) {
    const result = delta.clone();
    result.merge(previous);
    return result;
  }
  /**
   * Returns a new DELTA aggregation by comparing two cumulative measurements.
   */
  diff(previous, current) {
    const result = current.clone();
    result.diff(previous);
    return result;
  }
  toMetricData(descriptor, aggregationTemporality, accumulationByAttributes, endTime) {
    return {
      descriptor,
      aggregationTemporality,
      dataPointType: DataPointType.EXPONENTIAL_HISTOGRAM,
      dataPoints: accumulationByAttributes.map(([attributes, accumulation]) => {
        const pointValue = accumulation.toPointValue();
        const allowsNegativeValues = descriptor.type === InstrumentType.GAUGE || descriptor.type === InstrumentType.UP_DOWN_COUNTER || descriptor.type === InstrumentType.OBSERVABLE_GAUGE || descriptor.type === InstrumentType.OBSERVABLE_UP_DOWN_COUNTER;
        return {
          attributes,
          startTime: accumulation.startTime,
          endTime,
          value: {
            min: pointValue.hasMinMax ? pointValue.min : void 0,
            max: pointValue.hasMinMax ? pointValue.max : void 0,
            sum: !allowsNegativeValues ? pointValue.sum : void 0,
            positive: {
              offset: pointValue.positive.offset,
              bucketCounts: pointValue.positive.bucketCounts
            },
            negative: {
              offset: pointValue.negative.offset,
              bucketCounts: pointValue.negative.bucketCounts
            },
            count: pointValue.count,
            scale: pointValue.scale,
            zeroCount: pointValue.zeroCount
          }
        };
      })
    };
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/LastValue.js
var LastValueAccumulation = class {
  startTime;
  _current;
  sampleTime;
  constructor(startTime, _current = 0, sampleTime = [0, 0]) {
    this.startTime = startTime;
    this._current = _current;
    this.sampleTime = sampleTime;
  }
  record(value) {
    this._current = value;
    this.sampleTime = millisToHrTime(Date.now());
  }
  setStartTime(startTime) {
    this.startTime = startTime;
  }
  toPointValue() {
    return this._current;
  }
};
var LastValueAggregator = class {
  kind = AggregatorKind.LAST_VALUE;
  createAccumulation(startTime) {
    return new LastValueAccumulation(startTime);
  }
  /**
   * Returns the result of the merge of the given accumulations.
   *
   * Return the newly captured (delta) accumulation for LastValueAggregator.
   */
  merge(previous, delta) {
    const latestAccumulation = hrTimeToMicroseconds(delta.sampleTime) >= hrTimeToMicroseconds(previous.sampleTime) ? delta : previous;
    return new LastValueAccumulation(previous.startTime, latestAccumulation.toPointValue(), latestAccumulation.sampleTime);
  }
  /**
   * Returns a new DELTA aggregation by comparing two cumulative measurements.
   *
   * A delta aggregation is not meaningful to LastValueAggregator, just return
   * the newly captured (delta) accumulation for LastValueAggregator.
   */
  diff(previous, current) {
    const latestAccumulation = hrTimeToMicroseconds(current.sampleTime) >= hrTimeToMicroseconds(previous.sampleTime) ? current : previous;
    return new LastValueAccumulation(current.startTime, latestAccumulation.toPointValue(), latestAccumulation.sampleTime);
  }
  toMetricData(descriptor, aggregationTemporality, accumulationByAttributes, endTime) {
    return {
      descriptor,
      aggregationTemporality,
      dataPointType: DataPointType.GAUGE,
      dataPoints: accumulationByAttributes.map(([attributes, accumulation]) => {
        return {
          attributes,
          startTime: accumulation.startTime,
          endTime,
          value: accumulation.toPointValue()
        };
      })
    };
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/aggregator/Sum.js
var SumAccumulation = class {
  startTime;
  monotonic;
  _current;
  reset;
  constructor(startTime, monotonic, _current = 0, reset = false) {
    this.startTime = startTime;
    this.monotonic = monotonic;
    this._current = _current;
    this.reset = reset;
  }
  record(value) {
    if (this.monotonic && value < 0) {
      return;
    }
    this._current += value;
  }
  setStartTime(startTime) {
    this.startTime = startTime;
  }
  toPointValue() {
    return this._current;
  }
};
var SumAggregator = class {
  monotonic;
  kind = AggregatorKind.SUM;
  constructor(monotonic) {
    this.monotonic = monotonic;
  }
  createAccumulation(startTime) {
    return new SumAccumulation(startTime, this.monotonic);
  }
  /**
   * Returns the result of the merge of the given accumulations.
   */
  merge(previous, delta) {
    const prevPv = previous.toPointValue();
    const deltaPv = delta.toPointValue();
    if (delta.reset) {
      return new SumAccumulation(delta.startTime, this.monotonic, deltaPv, delta.reset);
    }
    return new SumAccumulation(previous.startTime, this.monotonic, prevPv + deltaPv);
  }
  /**
   * Returns a new DELTA aggregation by comparing two cumulative measurements.
   */
  diff(previous, current) {
    const prevPv = previous.toPointValue();
    const currPv = current.toPointValue();
    if (this.monotonic && prevPv > currPv) {
      return new SumAccumulation(current.startTime, this.monotonic, currPv, true);
    }
    return new SumAccumulation(current.startTime, this.monotonic, currPv - prevPv);
  }
  toMetricData(descriptor, aggregationTemporality, accumulationByAttributes, endTime) {
    return {
      descriptor,
      aggregationTemporality,
      dataPointType: DataPointType.SUM,
      dataPoints: accumulationByAttributes.map(([attributes, accumulation]) => {
        return {
          attributes,
          startTime: accumulation.startTime,
          endTime,
          value: accumulation.toPointValue()
        };
      }),
      isMonotonic: this.monotonic
    };
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/Aggregation.js
var DropAggregation = class _DropAggregation {
  static DEFAULT_INSTANCE = new DropAggregator();
  createAggregator(_instrument) {
    return _DropAggregation.DEFAULT_INSTANCE;
  }
};
var SumAggregation = class _SumAggregation {
  static MONOTONIC_INSTANCE = new SumAggregator(true);
  static NON_MONOTONIC_INSTANCE = new SumAggregator(false);
  createAggregator(instrument) {
    switch (instrument.type) {
      case InstrumentType.COUNTER:
      case InstrumentType.OBSERVABLE_COUNTER:
      case InstrumentType.HISTOGRAM: {
        return _SumAggregation.MONOTONIC_INSTANCE;
      }
      default: {
        return _SumAggregation.NON_MONOTONIC_INSTANCE;
      }
    }
  }
};
var LastValueAggregation = class _LastValueAggregation {
  static DEFAULT_INSTANCE = new LastValueAggregator();
  createAggregator(_instrument) {
    return _LastValueAggregation.DEFAULT_INSTANCE;
  }
};
var HistogramAggregation = class _HistogramAggregation {
  static DEFAULT_INSTANCE = new HistogramAggregator([0, 5, 10, 25, 50, 75, 100, 250, 500, 750, 1e3, 2500, 5e3, 7500, 1e4], true);
  createAggregator(_instrument) {
    return _HistogramAggregation.DEFAULT_INSTANCE;
  }
};
var ExplicitBucketHistogramAggregation = class {
  _recordMinMax;
  _boundaries;
  /**
   * @param boundaries the bucket boundaries of the histogram aggregation
   * @param _recordMinMax If set to true, min and max will be recorded. Otherwise, min and max will not be recorded.
   */
  constructor(boundaries, _recordMinMax = true) {
    this._recordMinMax = _recordMinMax;
    if (boundaries == null) {
      throw new Error("ExplicitBucketHistogramAggregation should be created with explicit boundaries, if a single bucket histogram is required, please pass an empty array");
    }
    boundaries = boundaries.concat();
    boundaries = boundaries.sort((a, b) => a - b);
    const minusInfinityIndex = boundaries.lastIndexOf(-Infinity);
    let infinityIndex = boundaries.indexOf(Infinity);
    if (infinityIndex === -1) {
      infinityIndex = void 0;
    }
    this._boundaries = boundaries.slice(minusInfinityIndex + 1, infinityIndex);
  }
  createAggregator(_instrument) {
    return new HistogramAggregator(this._boundaries, this._recordMinMax);
  }
};
var ExponentialHistogramAggregation = class {
  _maxSize;
  _recordMinMax;
  constructor(_maxSize = 160, _recordMinMax = true) {
    this._maxSize = _maxSize;
    this._recordMinMax = _recordMinMax;
  }
  createAggregator(_instrument) {
    return new ExponentialHistogramAggregator(this._maxSize, this._recordMinMax);
  }
};
var DefaultAggregation = class {
  _resolve(instrument) {
    switch (instrument.type) {
      case InstrumentType.COUNTER:
      case InstrumentType.UP_DOWN_COUNTER:
      case InstrumentType.OBSERVABLE_COUNTER:
      case InstrumentType.OBSERVABLE_UP_DOWN_COUNTER: {
        return SUM_AGGREGATION;
      }
      case InstrumentType.GAUGE:
      case InstrumentType.OBSERVABLE_GAUGE: {
        return LAST_VALUE_AGGREGATION;
      }
      case InstrumentType.HISTOGRAM: {
        if (instrument.advice.explicitBucketBoundaries) {
          return new ExplicitBucketHistogramAggregation(instrument.advice.explicitBucketBoundaries);
        }
        return HISTOGRAM_AGGREGATION;
      }
    }
    diag.warn(`Unable to recognize instrument type: ${instrument.type}`);
    return DROP_AGGREGATION;
  }
  createAggregator(instrument) {
    return this._resolve(instrument).createAggregator(instrument);
  }
};
var DROP_AGGREGATION = new DropAggregation();
var SUM_AGGREGATION = new SumAggregation();
var LAST_VALUE_AGGREGATION = new LastValueAggregation();
var HISTOGRAM_AGGREGATION = new HistogramAggregation();
var EXPONENTIAL_HISTOGRAM_AGGREGATION = new ExponentialHistogramAggregation();
var DEFAULT_AGGREGATION = new DefaultAggregation();

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/AggregationOption.js
var AggregationType;
(function(AggregationType2) {
  AggregationType2[AggregationType2["DEFAULT"] = 0] = "DEFAULT";
  AggregationType2[AggregationType2["DROP"] = 1] = "DROP";
  AggregationType2[AggregationType2["SUM"] = 2] = "SUM";
  AggregationType2[AggregationType2["LAST_VALUE"] = 3] = "LAST_VALUE";
  AggregationType2[AggregationType2["EXPLICIT_BUCKET_HISTOGRAM"] = 4] = "EXPLICIT_BUCKET_HISTOGRAM";
  AggregationType2[AggregationType2["EXPONENTIAL_HISTOGRAM"] = 5] = "EXPONENTIAL_HISTOGRAM";
})(AggregationType || (AggregationType = {}));
function toAggregation(option) {
  switch (option.type) {
    case AggregationType.DEFAULT:
      return DEFAULT_AGGREGATION;
    case AggregationType.DROP:
      return DROP_AGGREGATION;
    case AggregationType.SUM:
      return SUM_AGGREGATION;
    case AggregationType.LAST_VALUE:
      return LAST_VALUE_AGGREGATION;
    case AggregationType.EXPONENTIAL_HISTOGRAM: {
      const expOption = option;
      return new ExponentialHistogramAggregation(expOption.options?.maxSize, expOption.options?.recordMinMax);
    }
    case AggregationType.EXPLICIT_BUCKET_HISTOGRAM: {
      const expOption = option;
      if (expOption.options == null) {
        return HISTOGRAM_AGGREGATION;
      } else {
        return new ExplicitBucketHistogramAggregation(expOption.options?.boundaries, expOption.options?.recordMinMax);
      }
    }
    default:
      throw new Error("Unsupported Aggregation");
  }
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/AggregationSelector.js
var DEFAULT_AGGREGATION_SELECTOR = (_instrumentType) => {
  return {
    type: AggregationType.DEFAULT
  };
};
var DEFAULT_AGGREGATION_TEMPORALITY_SELECTOR = (_instrumentType) => AggregationTemporality.CUMULATIVE;

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/MetricReader.js
var MetricReader = class {
  // Tracks the shutdown state.
  // TODO: use BindOncePromise here once a new version of @opentelemetry/core is available.
  _shutdown = false;
  // Additional MetricProducers which will be combined with the SDK's output
  _metricProducers;
  // MetricProducer used by this instance which produces metrics from the SDK
  _sdkMetricProducer;
  _aggregationTemporalitySelector;
  _aggregationSelector;
  _cardinalitySelector;
  constructor(options) {
    this._aggregationSelector = options?.aggregationSelector ?? DEFAULT_AGGREGATION_SELECTOR;
    this._aggregationTemporalitySelector = options?.aggregationTemporalitySelector ?? DEFAULT_AGGREGATION_TEMPORALITY_SELECTOR;
    this._metricProducers = options?.metricProducers ?? [];
    this._cardinalitySelector = options?.cardinalitySelector;
  }
  setMetricProducer(metricProducer) {
    if (this._sdkMetricProducer) {
      throw new Error("MetricReader can not be bound to a MeterProvider again.");
    }
    this._sdkMetricProducer = metricProducer;
    this.onInitialized();
  }
  selectAggregation(instrumentType) {
    return this._aggregationSelector(instrumentType);
  }
  selectAggregationTemporality(instrumentType) {
    return this._aggregationTemporalitySelector(instrumentType);
  }
  selectCardinalityLimit(instrumentType) {
    return this._cardinalitySelector ? this._cardinalitySelector(instrumentType) : 2e3;
  }
  /**
   * Handle once the SDK has initialized this {@link MetricReader}
   * Overriding this method is optional.
   */
  onInitialized() {
  }
  async collect(options) {
    if (this._sdkMetricProducer === void 0) {
      throw new Error("MetricReader is not bound to a MetricProducer");
    }
    if (this._shutdown) {
      throw new Error("MetricReader is shutdown");
    }
    const [sdkCollectionResults, ...additionalCollectionResults] = await Promise.all([
      this._sdkMetricProducer.collect({
        timeoutMillis: options?.timeoutMillis
      }),
      ...this._metricProducers.map((producer) => producer.collect({
        timeoutMillis: options?.timeoutMillis
      }))
    ]);
    const errors = sdkCollectionResults.errors.concat(FlatMap(additionalCollectionResults, (result) => result.errors));
    const resource = sdkCollectionResults.resourceMetrics.resource;
    const scopeMetrics = sdkCollectionResults.resourceMetrics.scopeMetrics.concat(FlatMap(additionalCollectionResults, (result) => result.resourceMetrics.scopeMetrics));
    return {
      resourceMetrics: {
        resource,
        scopeMetrics
      },
      errors
    };
  }
  async shutdown(options) {
    if (this._shutdown) {
      diag.error("Cannot call shutdown twice.");
      return;
    }
    if (options?.timeoutMillis == null) {
      await this.onShutdown();
    } else {
      await callWithTimeout(this.onShutdown(), options.timeoutMillis);
    }
    this._shutdown = true;
  }
  async forceFlush(options) {
    if (this._shutdown) {
      diag.warn("Cannot forceFlush on already shutdown MetricReader.");
      return;
    }
    if (options?.timeoutMillis == null) {
      await this.onForceFlush();
      return;
    }
    await callWithTimeout(this.onForceFlush(), options.timeoutMillis);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/PeriodicExportingMetricReader.js
var PeriodicExportingMetricReader = class extends MetricReader {
  _interval;
  _exporter;
  _exportInterval;
  _exportTimeout;
  constructor(options) {
    super({
      aggregationSelector: options.exporter.selectAggregation?.bind(options.exporter),
      aggregationTemporalitySelector: options.exporter.selectAggregationTemporality?.bind(options.exporter),
      metricProducers: options.metricProducers
    });
    if (options.exportIntervalMillis !== void 0 && options.exportIntervalMillis <= 0) {
      throw Error("exportIntervalMillis must be greater than 0");
    }
    if (options.exportTimeoutMillis !== void 0 && options.exportTimeoutMillis <= 0) {
      throw Error("exportTimeoutMillis must be greater than 0");
    }
    if (options.exportTimeoutMillis !== void 0 && options.exportIntervalMillis !== void 0 && options.exportIntervalMillis < options.exportTimeoutMillis) {
      throw Error("exportIntervalMillis must be greater than or equal to exportTimeoutMillis");
    }
    this._exportInterval = options.exportIntervalMillis ?? 6e4;
    this._exportTimeout = options.exportTimeoutMillis ?? 3e4;
    this._exporter = options.exporter;
  }
  async _runOnce() {
    try {
      await callWithTimeout(this._doRun(), this._exportTimeout);
    } catch (err) {
      if (err instanceof TimeoutError) {
        diag.error("Export took longer than %s milliseconds and timed out.", this._exportTimeout);
        return;
      }
      globalErrorHandler(err);
    }
  }
  async _doRun() {
    const { resourceMetrics, errors } = await this.collect({
      timeoutMillis: this._exportTimeout
    });
    if (errors.length > 0) {
      diag.error("PeriodicExportingMetricReader: metrics collection errors", ...errors);
    }
    if (resourceMetrics.resource.asyncAttributesPending) {
      try {
        await resourceMetrics.resource.waitForAsyncAttributes?.();
      } catch (e) {
        diag.debug("Error while resolving async portion of resource: ", e);
        globalErrorHandler(e);
      }
    }
    if (resourceMetrics.scopeMetrics.length === 0) {
      return;
    }
    const result = await internal._export(this._exporter, resourceMetrics);
    if (result.code !== ExportResultCode.SUCCESS) {
      throw new Error(`PeriodicExportingMetricReader: metrics export failed (error ${result.error})`);
    }
  }
  onInitialized() {
    this._interval = setInterval(() => {
      void this._runOnce();
    }, this._exportInterval);
    if (typeof this._interval !== "number") {
      this._interval.unref();
    }
  }
  async onForceFlush() {
    await this._runOnce();
    await this._exporter.forceFlush();
  }
  async onShutdown() {
    if (this._interval) {
      clearInterval(this._interval);
    }
    await this.onForceFlush();
    await this._exporter.shutdown();
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/InMemoryMetricExporter.js
var InMemoryMetricExporter = class {
  _shutdown = false;
  _aggregationTemporality;
  _metrics = [];
  constructor(aggregationTemporality) {
    this._aggregationTemporality = aggregationTemporality;
  }
  /**
   * @inheritedDoc
   */
  export(metrics, resultCallback) {
    if (this._shutdown) {
      setTimeout(() => resultCallback({ code: ExportResultCode.FAILED }), 0);
      return;
    }
    this._metrics.push(metrics);
    setTimeout(() => resultCallback({ code: ExportResultCode.SUCCESS }), 0);
  }
  /**
   * Returns all the collected resource metrics
   * @returns ResourceMetrics[]
   */
  getMetrics() {
    return this._metrics;
  }
  forceFlush() {
    return Promise.resolve();
  }
  reset() {
    this._metrics = [];
  }
  selectAggregationTemporality(_instrumentType) {
    return this._aggregationTemporality;
  }
  shutdown() {
    this._shutdown = true;
    return Promise.resolve();
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/export/ConsoleMetricExporter.js
var ConsoleMetricExporter = class _ConsoleMetricExporter {
  _shutdown = false;
  _temporalitySelector;
  constructor(options) {
    this._temporalitySelector = options?.temporalitySelector ?? DEFAULT_AGGREGATION_TEMPORALITY_SELECTOR;
  }
  export(metrics, resultCallback) {
    if (this._shutdown) {
      setImmediate(resultCallback, { code: ExportResultCode.FAILED });
      return;
    }
    return _ConsoleMetricExporter._sendMetrics(metrics, resultCallback);
  }
  forceFlush() {
    return Promise.resolve();
  }
  selectAggregationTemporality(_instrumentType) {
    return this._temporalitySelector(_instrumentType);
  }
  shutdown() {
    this._shutdown = true;
    return Promise.resolve();
  }
  static _sendMetrics(metrics, done) {
    for (const scopeMetrics of metrics.scopeMetrics) {
      for (const metric of scopeMetrics.metrics) {
        console.dir({
          descriptor: metric.descriptor,
          dataPointType: metric.dataPointType,
          dataPoints: metric.dataPoints
        }, { depth: null });
      }
    }
    done({ code: ExportResultCode.SUCCESS });
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/ViewRegistry.js
var ViewRegistry = class {
  _registeredViews = [];
  addView(view) {
    this._registeredViews.push(view);
  }
  findViews(instrument, meter) {
    const views = this._registeredViews.filter((registeredView) => {
      return this._matchInstrument(registeredView.instrumentSelector, instrument) && this._matchMeter(registeredView.meterSelector, meter);
    });
    return views;
  }
  _matchInstrument(selector, instrument) {
    return (selector.getType() === void 0 || instrument.type === selector.getType()) && selector.getNameFilter().match(instrument.name) && selector.getUnitFilter().match(instrument.unit);
  }
  _matchMeter(selector, meter) {
    return selector.getNameFilter().match(meter.name) && (meter.version === void 0 || selector.getVersionFilter().match(meter.version)) && (meter.schemaUrl === void 0 || selector.getSchemaUrlFilter().match(meter.schemaUrl));
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/InstrumentDescriptor.js
function createInstrumentDescriptor(name, type, options) {
  if (!isValidName(name)) {
    diag.warn(`Invalid metric name: "${name}". The metric name should be a ASCII string with a length no greater than 255 characters.`);
  }
  return {
    name,
    type,
    description: options?.description ?? "",
    unit: options?.unit ?? "",
    valueType: options?.valueType ?? ValueType.DOUBLE,
    advice: options?.advice ?? {}
  };
}
function createInstrumentDescriptorWithView(view, instrument) {
  return {
    name: view.name ?? instrument.name,
    description: view.description ?? instrument.description,
    type: instrument.type,
    unit: instrument.unit,
    valueType: instrument.valueType,
    advice: instrument.advice
  };
}
function isDescriptorCompatibleWith(descriptor, otherDescriptor) {
  return equalsCaseInsensitive(descriptor.name, otherDescriptor.name) && descriptor.unit === otherDescriptor.unit && descriptor.type === otherDescriptor.type && descriptor.valueType === otherDescriptor.valueType;
}
var NAME_REGEXP = /^[a-z][a-z0-9_.\-/]{0,254}$/i;
function isValidName(name) {
  return name.match(NAME_REGEXP) != null;
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/Instruments.js
var SyncInstrument = class {
  _writableMetricStorage;
  _descriptor;
  constructor(_writableMetricStorage, _descriptor) {
    this._writableMetricStorage = _writableMetricStorage;
    this._descriptor = _descriptor;
  }
  _record(value, attributes = {}, context2 = context.active()) {
    if (typeof value !== "number") {
      diag.warn(`non-number value provided to metric ${this._descriptor.name}: ${value}`);
      return;
    }
    if (this._descriptor.valueType === ValueType.INT && !Number.isInteger(value)) {
      diag.warn(`INT value type cannot accept a floating-point value for ${this._descriptor.name}, ignoring the fractional digits.`);
      value = Math.trunc(value);
      if (!Number.isInteger(value)) {
        return;
      }
    }
    this._writableMetricStorage.record(value, attributes, context2, millisToHrTime(Date.now()));
  }
};
var UpDownCounterInstrument = class extends SyncInstrument {
  /**
   * Increment value of counter by the input. Inputs may be negative.
   */
  add(value, attributes, ctx) {
    this._record(value, attributes, ctx);
  }
};
var CounterInstrument = class extends SyncInstrument {
  /**
   * Increment value of counter by the input. Inputs may not be negative.
   */
  add(value, attributes, ctx) {
    if (value < 0) {
      diag.warn(`negative value provided to counter ${this._descriptor.name}: ${value}`);
      return;
    }
    this._record(value, attributes, ctx);
  }
};
var GaugeInstrument = class extends SyncInstrument {
  /**
   * Records a measurement.
   */
  record(value, attributes, ctx) {
    this._record(value, attributes, ctx);
  }
};
var HistogramInstrument = class extends SyncInstrument {
  /**
   * Records a measurement. Value of the measurement must not be negative.
   */
  record(value, attributes, ctx) {
    if (value < 0) {
      diag.warn(`negative value provided to histogram ${this._descriptor.name}: ${value}`);
      return;
    }
    this._record(value, attributes, ctx);
  }
};
var ObservableInstrument = class {
  _observableRegistry;
  /** @internal */
  _metricStorages;
  /** @internal */
  _descriptor;
  constructor(descriptor, metricStorages, _observableRegistry) {
    this._observableRegistry = _observableRegistry;
    this._descriptor = descriptor;
    this._metricStorages = metricStorages;
  }
  /**
   * @see {Observable.addCallback}
   */
  addCallback(callback) {
    this._observableRegistry.addCallback(callback, this);
  }
  /**
   * @see {Observable.removeCallback}
   */
  removeCallback(callback) {
    this._observableRegistry.removeCallback(callback, this);
  }
};
var ObservableCounterInstrument = class extends ObservableInstrument {
};
var ObservableGaugeInstrument = class extends ObservableInstrument {
};
var ObservableUpDownCounterInstrument = class extends ObservableInstrument {
};
function isObservableInstrument(it) {
  return it instanceof ObservableInstrument;
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/Meter.js
var Meter = class {
  _meterSharedState;
  constructor(_meterSharedState) {
    this._meterSharedState = _meterSharedState;
  }
  /**
   * Create a {@link Gauge} instrument.
   */
  createGauge(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.GAUGE, options);
    const storage = this._meterSharedState.registerMetricStorage(descriptor);
    return new GaugeInstrument(storage, descriptor);
  }
  /**
   * Create a {@link Histogram} instrument.
   */
  createHistogram(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.HISTOGRAM, options);
    const storage = this._meterSharedState.registerMetricStorage(descriptor);
    return new HistogramInstrument(storage, descriptor);
  }
  /**
   * Create a {@link Counter} instrument.
   */
  createCounter(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.COUNTER, options);
    const storage = this._meterSharedState.registerMetricStorage(descriptor);
    return new CounterInstrument(storage, descriptor);
  }
  /**
   * Create a {@link UpDownCounter} instrument.
   */
  createUpDownCounter(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.UP_DOWN_COUNTER, options);
    const storage = this._meterSharedState.registerMetricStorage(descriptor);
    return new UpDownCounterInstrument(storage, descriptor);
  }
  /**
   * Create a {@link ObservableGauge} instrument.
   */
  createObservableGauge(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.OBSERVABLE_GAUGE, options);
    const storages = this._meterSharedState.registerAsyncMetricStorage(descriptor);
    return new ObservableGaugeInstrument(descriptor, storages, this._meterSharedState.observableRegistry);
  }
  /**
   * Create a {@link ObservableCounter} instrument.
   */
  createObservableCounter(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.OBSERVABLE_COUNTER, options);
    const storages = this._meterSharedState.registerAsyncMetricStorage(descriptor);
    return new ObservableCounterInstrument(descriptor, storages, this._meterSharedState.observableRegistry);
  }
  /**
   * Create a {@link ObservableUpDownCounter} instrument.
   */
  createObservableUpDownCounter(name, options) {
    const descriptor = createInstrumentDescriptor(name, InstrumentType.OBSERVABLE_UP_DOWN_COUNTER, options);
    const storages = this._meterSharedState.registerAsyncMetricStorage(descriptor);
    return new ObservableUpDownCounterInstrument(descriptor, storages, this._meterSharedState.observableRegistry);
  }
  /**
   * @see {@link Meter.addBatchObservableCallback}
   */
  addBatchObservableCallback(callback, observables) {
    this._meterSharedState.observableRegistry.addBatchCallback(callback, observables);
  }
  /**
   * @see {@link Meter.removeBatchObservableCallback}
   */
  removeBatchObservableCallback(callback, observables) {
    this._meterSharedState.observableRegistry.removeBatchCallback(callback, observables);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/MetricStorage.js
var MetricStorage = class {
  _instrumentDescriptor;
  constructor(_instrumentDescriptor) {
    this._instrumentDescriptor = _instrumentDescriptor;
  }
  getInstrumentDescriptor() {
    return this._instrumentDescriptor;
  }
  updateDescription(description) {
    this._instrumentDescriptor = createInstrumentDescriptor(this._instrumentDescriptor.name, this._instrumentDescriptor.type, {
      description,
      valueType: this._instrumentDescriptor.valueType,
      unit: this._instrumentDescriptor.unit,
      advice: this._instrumentDescriptor.advice
    });
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/HashMap.js
var HashMap = class {
  _hash;
  _valueMap = /* @__PURE__ */ new Map();
  _keyMap = /* @__PURE__ */ new Map();
  constructor(_hash) {
    this._hash = _hash;
  }
  get(key, hashCode) {
    hashCode ??= this._hash(key);
    return this._valueMap.get(hashCode);
  }
  getOrDefault(key, defaultFactory) {
    const hash = this._hash(key);
    if (this._valueMap.has(hash)) {
      return this._valueMap.get(hash);
    }
    const val = defaultFactory();
    if (!this._keyMap.has(hash)) {
      this._keyMap.set(hash, key);
    }
    this._valueMap.set(hash, val);
    return val;
  }
  set(key, value, hashCode) {
    hashCode ??= this._hash(key);
    if (!this._keyMap.has(hashCode)) {
      this._keyMap.set(hashCode, key);
    }
    this._valueMap.set(hashCode, value);
  }
  has(key, hashCode) {
    hashCode ??= this._hash(key);
    return this._valueMap.has(hashCode);
  }
  *keys() {
    const keyIterator = this._keyMap.entries();
    let next = keyIterator.next();
    while (next.done !== true) {
      yield [next.value[1], next.value[0]];
      next = keyIterator.next();
    }
  }
  *entries() {
    const valueIterator = this._valueMap.entries();
    let next = valueIterator.next();
    while (next.done !== true) {
      yield [this._keyMap.get(next.value[0]), next.value[1], next.value[0]];
      next = valueIterator.next();
    }
  }
  get size() {
    return this._valueMap.size;
  }
};
var AttributeHashMap = class extends HashMap {
  constructor() {
    super(hashAttributes);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/DeltaMetricProcessor.js
var DeltaMetricProcessor = class {
  _aggregator;
  _activeCollectionStorage = new AttributeHashMap();
  // TODO: find a reasonable mean to clean the memo;
  // https://github.com/open-telemetry/opentelemetry-specification/pull/2208
  _cumulativeMemoStorage = new AttributeHashMap();
  _cardinalityLimit;
  _overflowAttributes = { "otel.metric.overflow": true };
  _overflowHashCode;
  constructor(_aggregator, aggregationCardinalityLimit) {
    this._aggregator = _aggregator;
    this._cardinalityLimit = (aggregationCardinalityLimit ?? 2e3) - 1;
    this._overflowHashCode = hashAttributes(this._overflowAttributes);
  }
  record(value, attributes, _context, collectionTime) {
    let accumulation = this._activeCollectionStorage.get(attributes);
    if (!accumulation) {
      if (this._activeCollectionStorage.size >= this._cardinalityLimit) {
        const overflowAccumulation = this._activeCollectionStorage.getOrDefault(this._overflowAttributes, () => this._aggregator.createAccumulation(collectionTime));
        overflowAccumulation?.record(value);
        return;
      }
      accumulation = this._aggregator.createAccumulation(collectionTime);
      this._activeCollectionStorage.set(attributes, accumulation);
    }
    accumulation?.record(value);
  }
  batchCumulate(measurements, collectionTime) {
    Array.from(measurements.entries()).forEach(([attributes, value, hashCode]) => {
      const accumulation = this._aggregator.createAccumulation(collectionTime);
      accumulation?.record(value);
      let delta = accumulation;
      if (this._cumulativeMemoStorage.has(attributes, hashCode)) {
        const previous = this._cumulativeMemoStorage.get(attributes, hashCode);
        delta = this._aggregator.diff(previous, accumulation);
      } else {
        if (this._cumulativeMemoStorage.size >= this._cardinalityLimit) {
          attributes = this._overflowAttributes;
          hashCode = this._overflowHashCode;
          if (this._cumulativeMemoStorage.has(attributes, hashCode)) {
            const previous = this._cumulativeMemoStorage.get(attributes, hashCode);
            delta = this._aggregator.diff(previous, accumulation);
          }
        }
      }
      if (this._activeCollectionStorage.has(attributes, hashCode)) {
        const active = this._activeCollectionStorage.get(attributes, hashCode);
        delta = this._aggregator.merge(active, delta);
      }
      this._cumulativeMemoStorage.set(attributes, accumulation, hashCode);
      this._activeCollectionStorage.set(attributes, delta, hashCode);
    });
  }
  /**
   * Returns a collection of delta metrics. Start time is the when first
   * time event collected.
   */
  collect() {
    const unreportedDelta = this._activeCollectionStorage;
    this._activeCollectionStorage = new AttributeHashMap();
    return unreportedDelta;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/TemporalMetricProcessor.js
var TemporalMetricProcessor = class _TemporalMetricProcessor {
  _aggregator;
  _unreportedAccumulations = /* @__PURE__ */ new Map();
  _reportHistory = /* @__PURE__ */ new Map();
  constructor(_aggregator, collectorHandles) {
    this._aggregator = _aggregator;
    collectorHandles.forEach((handle) => {
      this._unreportedAccumulations.set(handle, []);
    });
  }
  /**
   * Builds the {@link MetricData} streams to report against a specific MetricCollector.
   * @param collector The information of the MetricCollector.
   * @param collectors The registered collectors.
   * @param instrumentDescriptor The instrumentation descriptor that these metrics generated with.
   * @param currentAccumulations The current accumulation of metric data from instruments.
   * @param collectionTime The current collection timestamp.
   * @returns The {@link MetricData} points or `null`.
   */
  buildMetrics(collector, instrumentDescriptor, currentAccumulations, collectionTime) {
    this._stashAccumulations(currentAccumulations);
    const unreportedAccumulations = this._getMergedUnreportedAccumulations(collector);
    let result = unreportedAccumulations;
    let aggregationTemporality;
    if (this._reportHistory.has(collector)) {
      const last = this._reportHistory.get(collector);
      const lastCollectionTime = last.collectionTime;
      aggregationTemporality = last.aggregationTemporality;
      if (aggregationTemporality === AggregationTemporality.CUMULATIVE) {
        result = _TemporalMetricProcessor.merge(last.accumulations, unreportedAccumulations, this._aggregator);
      } else {
        result = _TemporalMetricProcessor.calibrateStartTime(last.accumulations, unreportedAccumulations, lastCollectionTime);
      }
    } else {
      aggregationTemporality = collector.selectAggregationTemporality(instrumentDescriptor.type);
    }
    this._reportHistory.set(collector, {
      accumulations: result,
      collectionTime,
      aggregationTemporality
    });
    const accumulationRecords = AttributesMapToAccumulationRecords(result);
    if (accumulationRecords.length === 0) {
      return void 0;
    }
    return this._aggregator.toMetricData(
      instrumentDescriptor,
      aggregationTemporality,
      accumulationRecords,
      /* endTime */
      collectionTime
    );
  }
  _stashAccumulations(currentAccumulation) {
    const registeredCollectors = this._unreportedAccumulations.keys();
    for (const collector of registeredCollectors) {
      let stash = this._unreportedAccumulations.get(collector);
      if (stash === void 0) {
        stash = [];
        this._unreportedAccumulations.set(collector, stash);
      }
      stash.push(currentAccumulation);
    }
  }
  _getMergedUnreportedAccumulations(collector) {
    let result = new AttributeHashMap();
    const unreportedList = this._unreportedAccumulations.get(collector);
    this._unreportedAccumulations.set(collector, []);
    if (unreportedList === void 0) {
      return result;
    }
    for (const it of unreportedList) {
      result = _TemporalMetricProcessor.merge(result, it, this._aggregator);
    }
    return result;
  }
  static merge(last, current, aggregator) {
    const result = last;
    const iterator = current.entries();
    let next = iterator.next();
    while (next.done !== true) {
      const [key, record, hash] = next.value;
      if (last.has(key, hash)) {
        const lastAccumulation = last.get(key, hash);
        const accumulation = aggregator.merge(lastAccumulation, record);
        result.set(key, accumulation, hash);
      } else {
        result.set(key, record, hash);
      }
      next = iterator.next();
    }
    return result;
  }
  /**
   * Calibrate the reported metric streams' startTime to lastCollectionTime. Leaves
   * the new stream to be the initial observation time unchanged.
   */
  static calibrateStartTime(last, current, lastCollectionTime) {
    for (const [key, hash] of last.keys()) {
      const currentAccumulation = current.get(key, hash);
      currentAccumulation?.setStartTime(lastCollectionTime);
    }
    return current;
  }
};
function AttributesMapToAccumulationRecords(map) {
  return Array.from(map.entries());
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/AsyncMetricStorage.js
var AsyncMetricStorage = class extends MetricStorage {
  _attributesProcessor;
  _aggregationCardinalityLimit;
  _deltaMetricStorage;
  _temporalMetricStorage;
  constructor(_instrumentDescriptor, aggregator, _attributesProcessor, collectorHandles, _aggregationCardinalityLimit) {
    super(_instrumentDescriptor);
    this._attributesProcessor = _attributesProcessor;
    this._aggregationCardinalityLimit = _aggregationCardinalityLimit;
    this._deltaMetricStorage = new DeltaMetricProcessor(aggregator, this._aggregationCardinalityLimit);
    this._temporalMetricStorage = new TemporalMetricProcessor(aggregator, collectorHandles);
  }
  record(measurements, observationTime) {
    const processed = new AttributeHashMap();
    Array.from(measurements.entries()).forEach(([attributes, value]) => {
      processed.set(this._attributesProcessor.process(attributes), value);
    });
    this._deltaMetricStorage.batchCumulate(processed, observationTime);
  }
  /**
   * Collects the metrics from this storage. The ObservableCallback is invoked
   * during the collection.
   *
   * Note: This is a stateful operation and may reset any interval-related
   * state for the MetricCollector.
   */
  collect(collector, collectionTime) {
    const accumulations = this._deltaMetricStorage.collect();
    return this._temporalMetricStorage.buildMetrics(collector, this._instrumentDescriptor, accumulations, collectionTime);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/RegistrationConflicts.js
function getIncompatibilityDetails(existing, otherDescriptor) {
  let incompatibility = "";
  if (existing.unit !== otherDescriptor.unit) {
    incompatibility += `	- Unit '${existing.unit}' does not match '${otherDescriptor.unit}'
`;
  }
  if (existing.type !== otherDescriptor.type) {
    incompatibility += `	- Type '${existing.type}' does not match '${otherDescriptor.type}'
`;
  }
  if (existing.valueType !== otherDescriptor.valueType) {
    incompatibility += `	- Value Type '${existing.valueType}' does not match '${otherDescriptor.valueType}'
`;
  }
  if (existing.description !== otherDescriptor.description) {
    incompatibility += `	- Description '${existing.description}' does not match '${otherDescriptor.description}'
`;
  }
  return incompatibility;
}
function getValueTypeConflictResolutionRecipe(existing, otherDescriptor) {
  return `	- use valueType '${existing.valueType}' on instrument creation or use an instrument name other than '${otherDescriptor.name}'`;
}
function getUnitConflictResolutionRecipe(existing, otherDescriptor) {
  return `	- use unit '${existing.unit}' on instrument creation or use an instrument name other than '${otherDescriptor.name}'`;
}
function getTypeConflictResolutionRecipe(existing, otherDescriptor) {
  const selector = {
    name: otherDescriptor.name,
    type: otherDescriptor.type,
    unit: otherDescriptor.unit
  };
  const selectorString = JSON.stringify(selector);
  return `	- create a new view with a name other than '${existing.name}' and InstrumentSelector '${selectorString}'`;
}
function getDescriptionResolutionRecipe(existing, otherDescriptor) {
  const selector = {
    name: otherDescriptor.name,
    type: otherDescriptor.type,
    unit: otherDescriptor.unit
  };
  const selectorString = JSON.stringify(selector);
  return `	- create a new view with a name other than '${existing.name}' and InstrumentSelector '${selectorString}'
    	- OR - create a new view with the name ${existing.name} and description '${existing.description}' and InstrumentSelector ${selectorString}
    	- OR - create a new view with the name ${otherDescriptor.name} and description '${existing.description}' and InstrumentSelector ${selectorString}`;
}
function getConflictResolutionRecipe(existing, otherDescriptor) {
  if (existing.valueType !== otherDescriptor.valueType) {
    return getValueTypeConflictResolutionRecipe(existing, otherDescriptor);
  }
  if (existing.unit !== otherDescriptor.unit) {
    return getUnitConflictResolutionRecipe(existing, otherDescriptor);
  }
  if (existing.type !== otherDescriptor.type) {
    return getTypeConflictResolutionRecipe(existing, otherDescriptor);
  }
  if (existing.description !== otherDescriptor.description) {
    return getDescriptionResolutionRecipe(existing, otherDescriptor);
  }
  return "";
}

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/MetricStorageRegistry.js
var MetricStorageRegistry = class _MetricStorageRegistry {
  _sharedRegistry = /* @__PURE__ */ new Map();
  _perCollectorRegistry = /* @__PURE__ */ new Map();
  static create() {
    return new _MetricStorageRegistry();
  }
  getStorages(collector) {
    let storages = [];
    for (const metricStorages of this._sharedRegistry.values()) {
      storages = storages.concat(metricStorages);
    }
    const perCollectorStorages = this._perCollectorRegistry.get(collector);
    if (perCollectorStorages != null) {
      for (const metricStorages of perCollectorStorages.values()) {
        storages = storages.concat(metricStorages);
      }
    }
    return storages;
  }
  register(storage) {
    this._registerStorage(storage, this._sharedRegistry);
  }
  registerForCollector(collector, storage) {
    let storageMap = this._perCollectorRegistry.get(collector);
    if (storageMap == null) {
      storageMap = /* @__PURE__ */ new Map();
      this._perCollectorRegistry.set(collector, storageMap);
    }
    this._registerStorage(storage, storageMap);
  }
  findOrUpdateCompatibleStorage(expectedDescriptor) {
    const storages = this._sharedRegistry.get(expectedDescriptor.name);
    if (storages === void 0) {
      return null;
    }
    return this._findOrUpdateCompatibleStorage(expectedDescriptor, storages);
  }
  findOrUpdateCompatibleCollectorStorage(collector, expectedDescriptor) {
    const storageMap = this._perCollectorRegistry.get(collector);
    if (storageMap === void 0) {
      return null;
    }
    const storages = storageMap.get(expectedDescriptor.name);
    if (storages === void 0) {
      return null;
    }
    return this._findOrUpdateCompatibleStorage(expectedDescriptor, storages);
  }
  _registerStorage(storage, storageMap) {
    const descriptor = storage.getInstrumentDescriptor();
    const storages = storageMap.get(descriptor.name);
    if (storages === void 0) {
      storageMap.set(descriptor.name, [storage]);
      return;
    }
    storages.push(storage);
  }
  _findOrUpdateCompatibleStorage(expectedDescriptor, existingStorages) {
    let compatibleStorage = null;
    for (const existingStorage of existingStorages) {
      const existingDescriptor = existingStorage.getInstrumentDescriptor();
      if (isDescriptorCompatibleWith(existingDescriptor, expectedDescriptor)) {
        if (existingDescriptor.description !== expectedDescriptor.description) {
          if (expectedDescriptor.description.length > existingDescriptor.description.length) {
            existingStorage.updateDescription(expectedDescriptor.description);
          }
          diag.warn("A view or instrument with the name ", expectedDescriptor.name, " has already been registered, but has a different description and is incompatible with another registered view.\n", "Details:\n", getIncompatibilityDetails(existingDescriptor, expectedDescriptor), "The longer description will be used.\nTo resolve the conflict:", getConflictResolutionRecipe(existingDescriptor, expectedDescriptor));
        }
        compatibleStorage = existingStorage;
      } else {
        diag.warn("A view or instrument with the name ", expectedDescriptor.name, " has already been registered and is incompatible with another registered view.\n", "Details:\n", getIncompatibilityDetails(existingDescriptor, expectedDescriptor), "To resolve the conflict:\n", getConflictResolutionRecipe(existingDescriptor, expectedDescriptor));
      }
    }
    return compatibleStorage;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/MultiWritableMetricStorage.js
var MultiMetricStorage = class {
  _backingStorages;
  constructor(_backingStorages) {
    this._backingStorages = _backingStorages;
  }
  record(value, attributes, context2, recordTime) {
    this._backingStorages.forEach((it) => {
      it.record(value, attributes, context2, recordTime);
    });
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/ObservableResult.js
var ObservableResultImpl = class {
  _instrumentName;
  _valueType;
  /**
   * @internal
   */
  _buffer = new AttributeHashMap();
  constructor(_instrumentName, _valueType) {
    this._instrumentName = _instrumentName;
    this._valueType = _valueType;
  }
  /**
   * Observe a measurement of the value associated with the given attributes.
   */
  observe(value, attributes = {}) {
    if (typeof value !== "number") {
      diag.warn(`non-number value provided to metric ${this._instrumentName}: ${value}`);
      return;
    }
    if (this._valueType === ValueType.INT && !Number.isInteger(value)) {
      diag.warn(`INT value type cannot accept a floating-point value for ${this._instrumentName}, ignoring the fractional digits.`);
      value = Math.trunc(value);
      if (!Number.isInteger(value)) {
        return;
      }
    }
    this._buffer.set(attributes, value);
  }
};
var BatchObservableResultImpl = class {
  /**
   * @internal
   */
  _buffer = /* @__PURE__ */ new Map();
  /**
   * Observe a measurement of the value associated with the given attributes.
   */
  observe(metric, value, attributes = {}) {
    if (!isObservableInstrument(metric)) {
      return;
    }
    let map = this._buffer.get(metric);
    if (map == null) {
      map = new AttributeHashMap();
      this._buffer.set(metric, map);
    }
    if (typeof value !== "number") {
      diag.warn(`non-number value provided to metric ${metric._descriptor.name}: ${value}`);
      return;
    }
    if (metric._descriptor.valueType === ValueType.INT && !Number.isInteger(value)) {
      diag.warn(`INT value type cannot accept a floating-point value for ${metric._descriptor.name}, ignoring the fractional digits.`);
      value = Math.trunc(value);
      if (!Number.isInteger(value)) {
        return;
      }
    }
    map.set(attributes, value);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/ObservableRegistry.js
var ObservableRegistry = class {
  _callbacks = [];
  _batchCallbacks = [];
  addCallback(callback, instrument) {
    const idx = this._findCallback(callback, instrument);
    if (idx >= 0) {
      return;
    }
    this._callbacks.push({ callback, instrument });
  }
  removeCallback(callback, instrument) {
    const idx = this._findCallback(callback, instrument);
    if (idx < 0) {
      return;
    }
    this._callbacks.splice(idx, 1);
  }
  addBatchCallback(callback, instruments) {
    const observableInstruments = new Set(instruments.filter(isObservableInstrument));
    if (observableInstruments.size === 0) {
      diag.error("BatchObservableCallback is not associated with valid instruments", instruments);
      return;
    }
    const idx = this._findBatchCallback(callback, observableInstruments);
    if (idx >= 0) {
      return;
    }
    this._batchCallbacks.push({ callback, instruments: observableInstruments });
  }
  removeBatchCallback(callback, instruments) {
    const observableInstruments = new Set(instruments.filter(isObservableInstrument));
    const idx = this._findBatchCallback(callback, observableInstruments);
    if (idx < 0) {
      return;
    }
    this._batchCallbacks.splice(idx, 1);
  }
  /**
   * @returns a promise of rejected reasons for invoking callbacks.
   */
  async observe(collectionTime, timeoutMillis) {
    const callbackFutures = this._observeCallbacks(collectionTime, timeoutMillis);
    const batchCallbackFutures = this._observeBatchCallbacks(collectionTime, timeoutMillis);
    const results = await PromiseAllSettled([
      ...callbackFutures,
      ...batchCallbackFutures
    ]);
    const rejections = results.filter(isPromiseAllSettledRejectionResult).map((it) => it.reason);
    return rejections;
  }
  _observeCallbacks(observationTime, timeoutMillis) {
    return this._callbacks.map(async ({ callback, instrument }) => {
      const observableResult = new ObservableResultImpl(instrument._descriptor.name, instrument._descriptor.valueType);
      let callPromise = Promise.resolve(callback(observableResult));
      if (timeoutMillis != null) {
        callPromise = callWithTimeout(callPromise, timeoutMillis);
      }
      await callPromise;
      instrument._metricStorages.forEach((metricStorage) => {
        metricStorage.record(observableResult._buffer, observationTime);
      });
    });
  }
  _observeBatchCallbacks(observationTime, timeoutMillis) {
    return this._batchCallbacks.map(async ({ callback, instruments }) => {
      const observableResult = new BatchObservableResultImpl();
      let callPromise = Promise.resolve(callback(observableResult));
      if (timeoutMillis != null) {
        callPromise = callWithTimeout(callPromise, timeoutMillis);
      }
      await callPromise;
      instruments.forEach((instrument) => {
        const buffer = observableResult._buffer.get(instrument);
        if (buffer == null) {
          return;
        }
        instrument._metricStorages.forEach((metricStorage) => {
          metricStorage.record(buffer, observationTime);
        });
      });
    });
  }
  _findCallback(callback, instrument) {
    return this._callbacks.findIndex((record) => {
      return record.callback === callback && record.instrument === instrument;
    });
  }
  _findBatchCallback(callback, instruments) {
    return this._batchCallbacks.findIndex((record) => {
      return record.callback === callback && setEquals(record.instruments, instruments);
    });
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/SyncMetricStorage.js
var SyncMetricStorage = class extends MetricStorage {
  _attributesProcessor;
  _aggregationCardinalityLimit;
  _deltaMetricStorage;
  _temporalMetricStorage;
  constructor(instrumentDescriptor, aggregator, _attributesProcessor, collectorHandles, _aggregationCardinalityLimit) {
    super(instrumentDescriptor);
    this._attributesProcessor = _attributesProcessor;
    this._aggregationCardinalityLimit = _aggregationCardinalityLimit;
    this._deltaMetricStorage = new DeltaMetricProcessor(aggregator, this._aggregationCardinalityLimit);
    this._temporalMetricStorage = new TemporalMetricProcessor(aggregator, collectorHandles);
  }
  record(value, attributes, context2, recordTime) {
    attributes = this._attributesProcessor.process(attributes, context2);
    this._deltaMetricStorage.record(value, attributes, context2, recordTime);
  }
  /**
   * Collects the metrics from this storage.
   *
   * Note: This is a stateful operation and may reset any interval-related
   * state for the MetricCollector.
   */
  collect(collector, collectionTime) {
    const accumulations = this._deltaMetricStorage.collect();
    return this._temporalMetricStorage.buildMetrics(collector, this._instrumentDescriptor, accumulations, collectionTime);
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/AttributesProcessor.js
var NoopAttributesProcessor = class {
  process(incoming, _context) {
    return incoming;
  }
};
var MultiAttributesProcessor = class {
  _processors;
  constructor(_processors) {
    this._processors = _processors;
  }
  process(incoming, context2) {
    let filteredAttributes = incoming;
    for (const processor of this._processors) {
      filteredAttributes = processor.process(filteredAttributes, context2);
    }
    return filteredAttributes;
  }
};
var AllowListProcessor = class {
  _allowedAttributeNames;
  constructor(_allowedAttributeNames) {
    this._allowedAttributeNames = _allowedAttributeNames;
  }
  process(incoming, _context) {
    const filteredAttributes = {};
    Object.keys(incoming).filter((attributeName) => this._allowedAttributeNames.includes(attributeName)).forEach((attributeName) => filteredAttributes[attributeName] = incoming[attributeName]);
    return filteredAttributes;
  }
};
var DenyListProcessor = class {
  _deniedAttributeNames;
  constructor(_deniedAttributeNames) {
    this._deniedAttributeNames = _deniedAttributeNames;
  }
  process(incoming, _context) {
    const filteredAttributes = {};
    Object.keys(incoming).filter((attributeName) => !this._deniedAttributeNames.includes(attributeName)).forEach((attributeName) => filteredAttributes[attributeName] = incoming[attributeName]);
    return filteredAttributes;
  }
};
function createNoopAttributesProcessor() {
  return NOOP;
}
function createMultiAttributesProcessor(processors) {
  return new MultiAttributesProcessor(processors);
}
function createAllowListAttributesProcessor(attributeAllowList) {
  return new AllowListProcessor(attributeAllowList);
}
function createDenyListAttributesProcessor(attributeDenyList) {
  return new DenyListProcessor(attributeDenyList);
}
var NOOP = new NoopAttributesProcessor();

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/MeterSharedState.js
var MeterSharedState = class {
  _meterProviderSharedState;
  _instrumentationScope;
  metricStorageRegistry = new MetricStorageRegistry();
  observableRegistry = new ObservableRegistry();
  meter;
  constructor(_meterProviderSharedState, _instrumentationScope) {
    this._meterProviderSharedState = _meterProviderSharedState;
    this._instrumentationScope = _instrumentationScope;
    this.meter = new Meter(this);
  }
  registerMetricStorage(descriptor) {
    const storages = this._registerMetricStorage(descriptor, SyncMetricStorage);
    if (storages.length === 1) {
      return storages[0];
    }
    return new MultiMetricStorage(storages);
  }
  registerAsyncMetricStorage(descriptor) {
    const storages = this._registerMetricStorage(descriptor, AsyncMetricStorage);
    return storages;
  }
  /**
   * @param collector opaque handle of {@link MetricCollector} which initiated the collection.
   * @param collectionTime the HrTime at which the collection was initiated.
   * @param options options for collection.
   * @returns the list of metric data collected.
   */
  async collect(collector, collectionTime, options) {
    const errors = await this.observableRegistry.observe(collectionTime, options?.timeoutMillis);
    const storages = this.metricStorageRegistry.getStorages(collector);
    if (storages.length === 0) {
      return null;
    }
    const metricDataList = storages.map((metricStorage) => {
      return metricStorage.collect(collector, collectionTime);
    }).filter(isNotNullish);
    if (metricDataList.length === 0) {
      return { errors };
    }
    return {
      scopeMetrics: {
        scope: this._instrumentationScope,
        metrics: metricDataList
      },
      errors
    };
  }
  _registerMetricStorage(descriptor, MetricStorageType) {
    const views = this._meterProviderSharedState.viewRegistry.findViews(descriptor, this._instrumentationScope);
    let storages = views.map((view) => {
      const viewDescriptor = createInstrumentDescriptorWithView(view, descriptor);
      const compatibleStorage = this.metricStorageRegistry.findOrUpdateCompatibleStorage(viewDescriptor);
      if (compatibleStorage != null) {
        return compatibleStorage;
      }
      const aggregator = view.aggregation.createAggregator(viewDescriptor);
      const viewStorage = new MetricStorageType(viewDescriptor, aggregator, view.attributesProcessor, this._meterProviderSharedState.metricCollectors, view.aggregationCardinalityLimit);
      this.metricStorageRegistry.register(viewStorage);
      return viewStorage;
    });
    if (storages.length === 0) {
      const perCollectorAggregations = this._meterProviderSharedState.selectAggregations(descriptor.type);
      const collectorStorages = perCollectorAggregations.map(([collector, aggregation]) => {
        const compatibleStorage = this.metricStorageRegistry.findOrUpdateCompatibleCollectorStorage(collector, descriptor);
        if (compatibleStorage != null) {
          return compatibleStorage;
        }
        const aggregator = aggregation.createAggregator(descriptor);
        const cardinalityLimit = collector.selectCardinalityLimit(descriptor.type);
        const storage = new MetricStorageType(descriptor, aggregator, createNoopAttributesProcessor(), [collector], cardinalityLimit);
        this.metricStorageRegistry.registerForCollector(collector, storage);
        return storage;
      });
      storages = storages.concat(collectorStorages);
    }
    return storages;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/MeterProviderSharedState.js
var MeterProviderSharedState = class {
  resource;
  viewRegistry = new ViewRegistry();
  metricCollectors = [];
  meterSharedStates = /* @__PURE__ */ new Map();
  constructor(resource) {
    this.resource = resource;
  }
  getMeterSharedState(instrumentationScope) {
    const id = instrumentationScopeId(instrumentationScope);
    let meterSharedState = this.meterSharedStates.get(id);
    if (meterSharedState == null) {
      meterSharedState = new MeterSharedState(this, instrumentationScope);
      this.meterSharedStates.set(id, meterSharedState);
    }
    return meterSharedState;
  }
  selectAggregations(instrumentType) {
    const result = [];
    for (const collector of this.metricCollectors) {
      result.push([
        collector,
        toAggregation(collector.selectAggregation(instrumentType))
      ]);
    }
    return result;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/state/MetricCollector.js
var MetricCollector = class {
  _sharedState;
  _metricReader;
  constructor(_sharedState, _metricReader) {
    this._sharedState = _sharedState;
    this._metricReader = _metricReader;
  }
  async collect(options) {
    const collectionTime = millisToHrTime(Date.now());
    const scopeMetrics = [];
    const errors = [];
    const meterCollectionPromises = Array.from(this._sharedState.meterSharedStates.values()).map(async (meterSharedState) => {
      const current = await meterSharedState.collect(this, collectionTime, options);
      if (current?.scopeMetrics != null) {
        scopeMetrics.push(current.scopeMetrics);
      }
      if (current?.errors != null) {
        errors.push(...current.errors);
      }
    });
    await Promise.all(meterCollectionPromises);
    return {
      resourceMetrics: {
        resource: this._sharedState.resource,
        scopeMetrics
      },
      errors
    };
  }
  /**
   * Delegates for MetricReader.forceFlush.
   */
  async forceFlush(options) {
    await this._metricReader.forceFlush(options);
  }
  /**
   * Delegates for MetricReader.shutdown.
   */
  async shutdown(options) {
    await this._metricReader.shutdown(options);
  }
  selectAggregationTemporality(instrumentType) {
    return this._metricReader.selectAggregationTemporality(instrumentType);
  }
  selectAggregation(instrumentType) {
    return this._metricReader.selectAggregation(instrumentType);
  }
  /**
   * Select the cardinality limit for the given {@link InstrumentType} for this
   * collector.
   */
  selectCardinalityLimit(instrumentType) {
    return this._metricReader.selectCardinalityLimit?.(instrumentType) ?? 2e3;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/Predicate.js
var ESCAPE = /[\^$\\.+?()[\]{}|]/g;
var PatternPredicate = class _PatternPredicate {
  _matchAll;
  _regexp;
  constructor(pattern) {
    if (pattern === "*") {
      this._matchAll = true;
      this._regexp = /.*/;
    } else {
      this._matchAll = false;
      this._regexp = new RegExp(_PatternPredicate.escapePattern(pattern));
    }
  }
  match(str) {
    if (this._matchAll) {
      return true;
    }
    return this._regexp.test(str);
  }
  static escapePattern(pattern) {
    return `^${pattern.replace(ESCAPE, "\\$&").replace("*", ".*")}$`;
  }
  static hasWildcard(pattern) {
    return pattern.includes("*");
  }
};
var ExactPredicate = class {
  _matchAll;
  _pattern;
  constructor(pattern) {
    this._matchAll = pattern === void 0;
    this._pattern = pattern;
  }
  match(str) {
    if (this._matchAll) {
      return true;
    }
    if (str === this._pattern) {
      return true;
    }
    return false;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/InstrumentSelector.js
var InstrumentSelector = class {
  _nameFilter;
  _type;
  _unitFilter;
  constructor(criteria) {
    this._nameFilter = new PatternPredicate(criteria?.name ?? "*");
    this._type = criteria?.type;
    this._unitFilter = new ExactPredicate(criteria?.unit);
  }
  getType() {
    return this._type;
  }
  getNameFilter() {
    return this._nameFilter;
  }
  getUnitFilter() {
    return this._unitFilter;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/MeterSelector.js
var MeterSelector = class {
  _nameFilter;
  _versionFilter;
  _schemaUrlFilter;
  constructor(criteria) {
    this._nameFilter = new ExactPredicate(criteria?.name);
    this._versionFilter = new ExactPredicate(criteria?.version);
    this._schemaUrlFilter = new ExactPredicate(criteria?.schemaUrl);
  }
  getNameFilter() {
    return this._nameFilter;
  }
  /**
   * TODO: semver filter? no spec yet.
   */
  getVersionFilter() {
    return this._versionFilter;
  }
  getSchemaUrlFilter() {
    return this._schemaUrlFilter;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/view/View.js
function isSelectorNotProvided(options) {
  return options.instrumentName == null && options.instrumentType == null && options.instrumentUnit == null && options.meterName == null && options.meterVersion == null && options.meterSchemaUrl == null;
}
function validateViewOptions(viewOptions) {
  if (isSelectorNotProvided(viewOptions)) {
    throw new Error("Cannot create view with no selector arguments supplied");
  }
  if (viewOptions.name != null && (viewOptions?.instrumentName == null || PatternPredicate.hasWildcard(viewOptions.instrumentName))) {
    throw new Error("Views with a specified name must be declared with an instrument selector that selects at most one instrument per meter.");
  }
}
var View = class {
  name;
  description;
  aggregation;
  attributesProcessor;
  instrumentSelector;
  meterSelector;
  aggregationCardinalityLimit;
  /**
   * Create a new {@link View} instance.
   *
   * Parameters can be categorized as two types:
   *  Instrument selection criteria: Used to describe the instrument(s) this view will be applied to.
   *  Will be treated as additive (the Instrument has to meet all the provided criteria to be selected).
   *
   *  Metric stream altering: Alter the metric stream of instruments selected by instrument selection criteria.
   *
   * @param viewOptions {@link ViewOptions} for altering the metric stream and instrument selection.
   * @param viewOptions.name
   * Alters the metric stream:
   *  This will be used as the name of the metrics stream.
   *  If not provided, the original Instrument name will be used.
   * @param viewOptions.description
   * Alters the metric stream:
   *  This will be used as the description of the metrics stream.
   *  If not provided, the original Instrument description will be used by default.
   * @param viewOptions.attributesProcessors
   * Alters the metric stream:
   *  If provided, the attributes will be modified as defined by the added processors.
   *  If not provided, all attribute keys will be used by default.
   * @param viewOptions.aggregationCardinalityLimit
   * Alters the metric stream:
   *  Sets a limit on the number of unique attribute combinations (cardinality) that can be aggregated.
   *  If not provided, the default limit of 2000 will be used.
   * @param viewOptions.aggregation
   * Alters the metric stream:
   *  Alters the {@link Aggregation} of the metric stream.
   * @param viewOptions.instrumentName
   * Instrument selection criteria:
   *  Original name of the Instrument(s) with wildcard support.
   * @param viewOptions.instrumentType
   * Instrument selection criteria:
   *  The original type of the Instrument(s).
   * @param viewOptions.instrumentUnit
   * Instrument selection criteria:
   *  The unit of the Instrument(s).
   * @param viewOptions.meterName
   * Instrument selection criteria:
   *  The name of the Meter. No wildcard support, name must match the meter exactly.
   * @param viewOptions.meterVersion
   * Instrument selection criteria:
   *  The version of the Meter. No wildcard support, version must match exactly.
   * @param viewOptions.meterSchemaUrl
   * Instrument selection criteria:
   *  The schema URL of the Meter. No wildcard support, schema URL must match exactly.
   *
   * @example
   * // Create a view that changes the Instrument 'my.instrument' to use to an
   * // ExplicitBucketHistogramAggregation with the boundaries [20, 30, 40]
   * new View({
   *   aggregation: new ExplicitBucketHistogramAggregation([20, 30, 40]),
   *   instrumentName: 'my.instrument'
   * })
   */
  constructor(viewOptions) {
    validateViewOptions(viewOptions);
    if (viewOptions.attributesProcessors != null) {
      this.attributesProcessor = createMultiAttributesProcessor(viewOptions.attributesProcessors);
    } else {
      this.attributesProcessor = createNoopAttributesProcessor();
    }
    this.name = viewOptions.name;
    this.description = viewOptions.description;
    this.aggregation = toAggregation(viewOptions.aggregation ?? { type: AggregationType.DEFAULT });
    this.instrumentSelector = new InstrumentSelector({
      name: viewOptions.instrumentName,
      type: viewOptions.instrumentType,
      unit: viewOptions.instrumentUnit
    });
    this.meterSelector = new MeterSelector({
      name: viewOptions.meterName,
      version: viewOptions.meterVersion,
      schemaUrl: viewOptions.meterSchemaUrl
    });
    this.aggregationCardinalityLimit = viewOptions.aggregationCardinalityLimit;
  }
};

// node_modules/.pnpm/@opentelemetry+sdk-metrics@2.2.0_@opentelemetry+api@1.9.0/node_modules/@opentelemetry/sdk-metrics/build/esm/MeterProvider.js
var MeterProvider = class {
  _sharedState;
  _shutdown = false;
  constructor(options) {
    this._sharedState = new MeterProviderSharedState(options?.resource ?? defaultResource());
    if (options?.views != null && options.views.length > 0) {
      for (const viewOption of options.views) {
        this._sharedState.viewRegistry.addView(new View(viewOption));
      }
    }
    if (options?.readers != null && options.readers.length > 0) {
      for (const metricReader of options.readers) {
        const collector = new MetricCollector(this._sharedState, metricReader);
        metricReader.setMetricProducer(collector);
        this._sharedState.metricCollectors.push(collector);
      }
    }
  }
  /**
   * Get a meter with the configuration of the MeterProvider.
   */
  getMeter(name, version = "", options = {}) {
    if (this._shutdown) {
      diag.warn("A shutdown MeterProvider cannot provide a Meter");
      return createNoopMeter();
    }
    return this._sharedState.getMeterSharedState({
      name,
      version,
      schemaUrl: options.schemaUrl
    }).meter;
  }
  /**
   * Shut down the MeterProvider and all registered
   * MetricReaders.
   *
   * Returns a promise which is resolved when all flushes are complete.
   */
  async shutdown(options) {
    if (this._shutdown) {
      diag.warn("shutdown may only be called once per MeterProvider");
      return;
    }
    this._shutdown = true;
    await Promise.all(this._sharedState.metricCollectors.map((collector) => {
      return collector.shutdown(options);
    }));
  }
  /**
   * Notifies all registered MetricReaders to flush any buffered data.
   *
   * Returns a promise which is resolved when all flushes are complete.
   */
  async forceFlush(options) {
    if (this._shutdown) {
      diag.warn("invalid attempt to force flush after MeterProvider shutdown");
      return;
    }
    await Promise.all(this._sharedState.metricCollectors.map((collector) => {
      return collector.forceFlush(options);
    }));
  }
};

export {
  AggregationTemporality,
  InstrumentType,
  DataPointType,
  TimeoutError,
  AggregationType,
  MetricReader,
  PeriodicExportingMetricReader,
  InMemoryMetricExporter,
  ConsoleMetricExporter,
  createAllowListAttributesProcessor,
  createDenyListAttributesProcessor,
  MeterProvider
};
//# sourceMappingURL=chunk-3QLT7M6V.js.map
